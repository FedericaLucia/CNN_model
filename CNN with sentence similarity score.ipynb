{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of E2E dataset with shuffled labeled dataset (fake and non fake reviews). The aim of this task is to generate a CNN model to classify sentences on the basis of the semantic similarity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# to update later\n",
    "from utils import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from numpy.linalg import norm\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import f1_score\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "seed = 10\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset already labeled and shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mr</th>\n",
       "      <th>ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>name cocum   eattype coffee shop   food englis...</td>\n",
       "      <td>cocum cheap chinese coffee shop family friendl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>name the eagle   customer rating 5 out of 5   ...</td>\n",
       "      <td>eagle city centre near café brazil family frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>name cotto   eattype coffee shop   food englis...</td>\n",
       "      <td>area riverside near portland arms cotto high p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>name the wrestlers   eattype coffee shop   foo...</td>\n",
       "      <td>wrestlers family friendly venue near sorrento ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>name the punter   customer rating average   ar...</td>\n",
       "      <td>punter family friendly place riverside area hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>name the phoenix   customer rating 5 out of 5 ...</td>\n",
       "      <td>5 5 rated phoenix located riverside area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>name the eagle   eattype coffee shop   food en...</td>\n",
       "      <td>eagle coffee shop eat chinese food cheaply fam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>name cocum   eattype coffee shop   food chines...</td>\n",
       "      <td>cocum family friendly coffee shop serves chine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>name the wrestlers   eattype coffee shop   foo...</td>\n",
       "      <td>wrestlers coffee shop located riverside near r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>name fitzbillies   eattype coffee shop   food ...</td>\n",
       "      <td>fitzbillies adult themed coffee shop located c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>name the eagle   eattype coffee shop   food en...</td>\n",
       "      <td>eagle coffee shop traditional british food nea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>name the mill   eattype coffee shop   food chi...</td>\n",
       "      <td>mill coffee shop sells cheap english food loca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>name the wrestlers   eattype coffee shop   foo...</td>\n",
       "      <td>wrestlers coffee shop provides chinese food mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>name the wrestlers   customer rating 5 out of ...</td>\n",
       "      <td>wrestlers near sorrento recommended least chil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>name the punter   customer rating 5 out of 5  ...</td>\n",
       "      <td>punter friends riverside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>name cotto   eattype coffee shop   food chines...</td>\n",
       "      <td>english food served cotto city centre near por...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>name the eagle   customer rating low   area ri...</td>\n",
       "      <td>eagle riverside near café brazil family friend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>name the eagle   eattype coffee shop   food ch...</td>\n",
       "      <td>eagle coffee shop located near burger king riv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>name the wrestlers   eattype coffee shop   foo...</td>\n",
       "      <td>welcome wrestlers coffee shop price range mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>name cotto   eattype coffee shop   food englis...</td>\n",
       "      <td>located river near portland arms cotto offers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>name aromi   eattype coffee shop   food chines...</td>\n",
       "      <td>located river aromi british coffee shop servin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>name the cricketers   eattype coffee shop   fo...</td>\n",
       "      <td>cricketers english food coffee shop located ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>name aromi   eattype coffee shop   food englis...</td>\n",
       "      <td>near riverside find coffee shop called aromi s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>name taste of cambridge   eattype coffee shop ...</td>\n",
       "      <td>taste cambridge coffee shop located near crown...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>name the wrestlers   customer rating 3 out of ...</td>\n",
       "      <td>near sorrento wrestlers customer rating 3out 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>name wildwood   eattype coffee shop   food chi...</td>\n",
       "      <td>wildwood english coffee shop average customer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>name the wrestlers   customer rating low   fam...</td>\n",
       "      <td>wrestlers family friendly restaurant found nea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>name fitzbillies   eattype coffee shop   food ...</td>\n",
       "      <td>fitzbillies serves chinese food riverside area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>name the wrestlers   eattype coffee shop   foo...</td>\n",
       "      <td>wrestlers family friendly 5 5 customer rating ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>name the eagle   eattype coffee shop   food ch...</td>\n",
       "      <td>eagle 1 5 coffee shop serves chinese food high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9314</th>\n",
       "      <td>1</td>\n",
       "      <td>name the eagle   eattype coffee shop   food ch...</td>\n",
       "      <td>eagle one star family friendly coffee shop loc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9315</th>\n",
       "      <td>1</td>\n",
       "      <td>name the wrestlers   eattype coffee shop   foo...</td>\n",
       "      <td>wrestlers coffee shop providing english food l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9316</th>\n",
       "      <td>1</td>\n",
       "      <td>name travellers rest beefeater   customer rati...</td>\n",
       "      <td>travellers rest beefeater near raja indian cui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9317</th>\n",
       "      <td>1</td>\n",
       "      <td>name the mill   eattype coffee shop   food chi...</td>\n",
       "      <td>mill located near sorrento coffee shop serving...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9318</th>\n",
       "      <td>0</td>\n",
       "      <td>name browns cambridge   eattype coffee shop   ...</td>\n",
       "      <td>browns cambridge coffee shop serves chinese fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9319</th>\n",
       "      <td>0</td>\n",
       "      <td>name cocum   eattype coffee shop   food englis...</td>\n",
       "      <td>coffee shop cocum serves english food average ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9320</th>\n",
       "      <td>0</td>\n",
       "      <td>name cotto   eattype coffee shop   food englis...</td>\n",
       "      <td>cotto 1 5 rated coffee shop high priced englis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9321</th>\n",
       "      <td>0</td>\n",
       "      <td>name fitzbillies   eattype coffee shop   food ...</td>\n",
       "      <td>something little upmarket try fitzbillies city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9322</th>\n",
       "      <td>1</td>\n",
       "      <td>name the wrestlers   customer rating average  ...</td>\n",
       "      <td>£20 eat wrestlers riverside family friendly co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9323</th>\n",
       "      <td>1</td>\n",
       "      <td>name the punter   customer rating average   ar...</td>\n",
       "      <td>punter coffee shop offers chinese food moderat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9324</th>\n",
       "      <td>0</td>\n",
       "      <td>name the cricketers   eattype coffee shop   fo...</td>\n",
       "      <td>cricketers coffee shop near portland arms serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9325</th>\n",
       "      <td>1</td>\n",
       "      <td>name browns cambridge   eattype coffee shop   ...</td>\n",
       "      <td>browns cambridge coffee shop offers chinese fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9326</th>\n",
       "      <td>1</td>\n",
       "      <td>name browns cambridge   eattype coffee shop   ...</td>\n",
       "      <td>browns cambridge boasts five star rating famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9327</th>\n",
       "      <td>1</td>\n",
       "      <td>name the cambridge blue   eattype coffee shop ...</td>\n",
       "      <td>coffee shop named cambridge blue family friend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9328</th>\n",
       "      <td>0</td>\n",
       "      <td>name the golden palace   eattype coffee shop  ...</td>\n",
       "      <td>english style coffee shop golden palace locate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9329</th>\n",
       "      <td>0</td>\n",
       "      <td>name cotto   eattype coffee shop   food englis...</td>\n",
       "      <td>cotto expensive coffee shop riverside near por...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9330</th>\n",
       "      <td>0</td>\n",
       "      <td>name the eagle   eattype coffee shop   food ch...</td>\n",
       "      <td>eagle coffee shop providing chinese food high ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9331</th>\n",
       "      <td>0</td>\n",
       "      <td>name alimentum   area riverside   familyfriend...</td>\n",
       "      <td>riverside near burger king kid friendly alimentum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9332</th>\n",
       "      <td>1</td>\n",
       "      <td>name the punter   eattype coffee shop   food c...</td>\n",
       "      <td>describing family friendly punter riverside co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9333</th>\n",
       "      <td>0</td>\n",
       "      <td>name the mill   eattype coffee shop   food chi...</td>\n",
       "      <td>mill moderately priced chinese coffee shop riv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9334</th>\n",
       "      <td>0</td>\n",
       "      <td>name the wrestlers   customer rating 3 out of ...</td>\n",
       "      <td>come eat 3 5 rated kid friendly restaurant cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9335</th>\n",
       "      <td>1</td>\n",
       "      <td>name the golden palace   eattype coffee shop  ...</td>\n",
       "      <td>golden palace coffee shop 1 5 customer rating ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9336</th>\n",
       "      <td>1</td>\n",
       "      <td>name the punter   eattype coffee shop   food e...</td>\n",
       "      <td>punter located near café sicilia chinese resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9337</th>\n",
       "      <td>0</td>\n",
       "      <td>name aromi   eattype coffee shop   food englis...</td>\n",
       "      <td>aromi coffee shop city center given customer r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9338</th>\n",
       "      <td>1</td>\n",
       "      <td>name the golden palace   eattype coffee shop  ...</td>\n",
       "      <td>golden palace coffee shop provides chinese foo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9339</th>\n",
       "      <td>0</td>\n",
       "      <td>name the wrestlers   customer rating 1 out of ...</td>\n",
       "      <td>near sorrento establishment 1 5 customer ratin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9340</th>\n",
       "      <td>0</td>\n",
       "      <td>name midsummer house   customer rating average...</td>\n",
       "      <td>looking restaurant average customer rating mid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9341</th>\n",
       "      <td>0</td>\n",
       "      <td>name aromi   eattype coffee shop   food chines...</td>\n",
       "      <td>riverside aromi coffee shop family friendly lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9342</th>\n",
       "      <td>0</td>\n",
       "      <td>name the eagle   eattype coffee shop   food en...</td>\n",
       "      <td>eagle english coffee shop near burger king riv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9343</th>\n",
       "      <td>0</td>\n",
       "      <td>name clowns   eattype coffee shop   food engli...</td>\n",
       "      <td>clowns coffee shop located near clare hall riv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9344 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                                 mr  \\\n",
       "0         1  name cocum   eattype coffee shop   food englis...   \n",
       "1         0  name the eagle   customer rating 5 out of 5   ...   \n",
       "2         0  name cotto   eattype coffee shop   food englis...   \n",
       "3         1  name the wrestlers   eattype coffee shop   foo...   \n",
       "4         1  name the punter   customer rating average   ar...   \n",
       "5         0  name the phoenix   customer rating 5 out of 5 ...   \n",
       "6         1  name the eagle   eattype coffee shop   food en...   \n",
       "7         1  name cocum   eattype coffee shop   food chines...   \n",
       "8         1  name the wrestlers   eattype coffee shop   foo...   \n",
       "9         0  name fitzbillies   eattype coffee shop   food ...   \n",
       "10        0  name the eagle   eattype coffee shop   food en...   \n",
       "11        1  name the mill   eattype coffee shop   food chi...   \n",
       "12        0  name the wrestlers   eattype coffee shop   foo...   \n",
       "13        1  name the wrestlers   customer rating 5 out of ...   \n",
       "14        0  name the punter   customer rating 5 out of 5  ...   \n",
       "15        1  name cotto   eattype coffee shop   food chines...   \n",
       "16        0  name the eagle   customer rating low   area ri...   \n",
       "17        1  name the eagle   eattype coffee shop   food ch...   \n",
       "18        0  name the wrestlers   eattype coffee shop   foo...   \n",
       "19        0  name cotto   eattype coffee shop   food englis...   \n",
       "20        1  name aromi   eattype coffee shop   food chines...   \n",
       "21        1  name the cricketers   eattype coffee shop   fo...   \n",
       "22        1  name aromi   eattype coffee shop   food englis...   \n",
       "23        1  name taste of cambridge   eattype coffee shop ...   \n",
       "24        0  name the wrestlers   customer rating 3 out of ...   \n",
       "25        1  name wildwood   eattype coffee shop   food chi...   \n",
       "26        0  name the wrestlers   customer rating low   fam...   \n",
       "27        0  name fitzbillies   eattype coffee shop   food ...   \n",
       "28        1  name the wrestlers   eattype coffee shop   foo...   \n",
       "29        0  name the eagle   eattype coffee shop   food ch...   \n",
       "...     ...                                                ...   \n",
       "9314      1  name the eagle   eattype coffee shop   food ch...   \n",
       "9315      1  name the wrestlers   eattype coffee shop   foo...   \n",
       "9316      1  name travellers rest beefeater   customer rati...   \n",
       "9317      1  name the mill   eattype coffee shop   food chi...   \n",
       "9318      0  name browns cambridge   eattype coffee shop   ...   \n",
       "9319      0  name cocum   eattype coffee shop   food englis...   \n",
       "9320      0  name cotto   eattype coffee shop   food englis...   \n",
       "9321      0  name fitzbillies   eattype coffee shop   food ...   \n",
       "9322      1  name the wrestlers   customer rating average  ...   \n",
       "9323      1  name the punter   customer rating average   ar...   \n",
       "9324      0  name the cricketers   eattype coffee shop   fo...   \n",
       "9325      1  name browns cambridge   eattype coffee shop   ...   \n",
       "9326      1  name browns cambridge   eattype coffee shop   ...   \n",
       "9327      1  name the cambridge blue   eattype coffee shop ...   \n",
       "9328      0  name the golden palace   eattype coffee shop  ...   \n",
       "9329      0  name cotto   eattype coffee shop   food englis...   \n",
       "9330      0  name the eagle   eattype coffee shop   food ch...   \n",
       "9331      0  name alimentum   area riverside   familyfriend...   \n",
       "9332      1  name the punter   eattype coffee shop   food c...   \n",
       "9333      0  name the mill   eattype coffee shop   food chi...   \n",
       "9334      0  name the wrestlers   customer rating 3 out of ...   \n",
       "9335      1  name the golden palace   eattype coffee shop  ...   \n",
       "9336      1  name the punter   eattype coffee shop   food e...   \n",
       "9337      0  name aromi   eattype coffee shop   food englis...   \n",
       "9338      1  name the golden palace   eattype coffee shop  ...   \n",
       "9339      0  name the wrestlers   customer rating 1 out of ...   \n",
       "9340      0  name midsummer house   customer rating average...   \n",
       "9341      0  name aromi   eattype coffee shop   food chines...   \n",
       "9342      0  name the eagle   eattype coffee shop   food en...   \n",
       "9343      0  name clowns   eattype coffee shop   food engli...   \n",
       "\n",
       "                                                    ref  \n",
       "0     cocum cheap chinese coffee shop family friendl...  \n",
       "1     eagle city centre near café brazil family frie...  \n",
       "2     area riverside near portland arms cotto high p...  \n",
       "3     wrestlers family friendly venue near sorrento ...  \n",
       "4     punter family friendly place riverside area hi...  \n",
       "5              5 5 rated phoenix located riverside area  \n",
       "6     eagle coffee shop eat chinese food cheaply fam...  \n",
       "7     cocum family friendly coffee shop serves chine...  \n",
       "8     wrestlers coffee shop located riverside near r...  \n",
       "9     fitzbillies adult themed coffee shop located c...  \n",
       "10    eagle coffee shop traditional british food nea...  \n",
       "11    mill coffee shop sells cheap english food loca...  \n",
       "12    wrestlers coffee shop provides chinese food mo...  \n",
       "13    wrestlers near sorrento recommended least chil...  \n",
       "14                             punter friends riverside  \n",
       "15    english food served cotto city centre near por...  \n",
       "16    eagle riverside near café brazil family friend...  \n",
       "17    eagle coffee shop located near burger king riv...  \n",
       "18    welcome wrestlers coffee shop price range mode...  \n",
       "19    located river near portland arms cotto offers ...  \n",
       "20    located river aromi british coffee shop servin...  \n",
       "21    cricketers english food coffee shop located ne...  \n",
       "22    near riverside find coffee shop called aromi s...  \n",
       "23    taste cambridge coffee shop located near crown...  \n",
       "24    near sorrento wrestlers customer rating 3out 5...  \n",
       "25    wildwood english coffee shop average customer ...  \n",
       "26    wrestlers family friendly restaurant found nea...  \n",
       "27    fitzbillies serves chinese food riverside area...  \n",
       "28    wrestlers family friendly 5 5 customer rating ...  \n",
       "29    eagle 1 5 coffee shop serves chinese food high...  \n",
       "...                                                 ...  \n",
       "9314  eagle one star family friendly coffee shop loc...  \n",
       "9315  wrestlers coffee shop providing english food l...  \n",
       "9316  travellers rest beefeater near raja indian cui...  \n",
       "9317  mill located near sorrento coffee shop serving...  \n",
       "9318  browns cambridge coffee shop serves chinese fo...  \n",
       "9319  coffee shop cocum serves english food average ...  \n",
       "9320  cotto 1 5 rated coffee shop high priced englis...  \n",
       "9321  something little upmarket try fitzbillies city...  \n",
       "9322  £20 eat wrestlers riverside family friendly co...  \n",
       "9323  punter coffee shop offers chinese food moderat...  \n",
       "9324  cricketers coffee shop near portland arms serv...  \n",
       "9325  browns cambridge coffee shop offers chinese fo...  \n",
       "9326  browns cambridge boasts five star rating famil...  \n",
       "9327  coffee shop named cambridge blue family friend...  \n",
       "9328  english style coffee shop golden palace locate...  \n",
       "9329  cotto expensive coffee shop riverside near por...  \n",
       "9330  eagle coffee shop providing chinese food high ...  \n",
       "9331  riverside near burger king kid friendly alimentum  \n",
       "9332  describing family friendly punter riverside co...  \n",
       "9333  mill moderately priced chinese coffee shop riv...  \n",
       "9334  come eat 3 5 rated kid friendly restaurant cal...  \n",
       "9335  golden palace coffee shop 1 5 customer rating ...  \n",
       "9336  punter located near café sicilia chinese resta...  \n",
       "9337  aromi coffee shop city center given customer r...  \n",
       "9338  golden palace coffee shop provides chinese foo...  \n",
       "9339  near sorrento establishment 1 5 customer ratin...  \n",
       "9340  looking restaurant average customer rating mid...  \n",
       "9341  riverside aromi coffee shop family friendly lo...  \n",
       "9342  eagle english coffee shop near burger king riv...  \n",
       "9343  clowns coffee shop located near clare hall riv...  \n",
       "\n",
       "[9344 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = pd.read_csv('data/dataframe.csv')\n",
    "\n",
    "data = data_path.drop(data_path.columns[0], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9344 entries, 0 to 9343\n",
      "Data columns (total 3 columns):\n",
      "label    9344 non-null int64\n",
      "mr       9344 non-null object\n",
      "ref      9344 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 219.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 9344 entries with the following data:\n",
    "1-'mr' : Meaning representation\n",
    "2-'ref' string containing the values in 'mr'\n",
    "3-label: 0 for non fake and 1 for fake reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras.backend as K\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from numpy.linalg import norm\n",
    "import csv\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "\n",
    "def reshape_data(mr_data, ref_data, y_data):\n",
    "    '''\n",
    "    Reshapes the input data.\n",
    "    :param mr_data: mr\n",
    "    :param ref_data: ref\n",
    "    :param y_data: output\n",
    "    :return: a reshaped mr, ref, output\n",
    "    '''\n",
    "    # mr\n",
    "    mr = np.array(mr_data)\n",
    "    mr = mr.reshape(mr.shape +  (1, ))\n",
    "    \n",
    "    # ref\n",
    "    ref = np.array(ref_data)\n",
    "    ref = ref.reshape(ref.shape + (1,))\n",
    "    \n",
    "    # y\n",
    "    y = np.array(y_data)\n",
    "    y  = y.reshape((y.shape[0], 1))\n",
    "    \n",
    "    return mr, ref, y\n",
    "\n",
    "\n",
    "\n",
    "def clean_str(txt):\n",
    "    '''\n",
    "    Cleans a text by removing all non alphanumeric characters.\n",
    "    :param txt: String, the input sentence.\n",
    "    :return: A cleaned sentence.\n",
    "    '''\n",
    "    txt = str(txt)\n",
    "    txt = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`&%]\", \" \", txt)\n",
    "    txt = re.sub(r\"\\'s\", \" \\'s\", txt)\n",
    "    txt = re.sub(r\"\\'ve\", \" \\'ve\", txt)\n",
    "    txt = re.sub(r\"\\'t\", \" n\\'t\", txt)\n",
    "    txt = re.sub(r\"\\'re\", \" \\'re\", txt)\n",
    "    txt = re.sub(r\"\\'d\", \" \\'d\", txt)\n",
    "    txt = re.sub(r\"\\'ll\", \" \\'ll\", txt)\n",
    "    txt = re.sub(r\",\", \" , \", txt)\n",
    "    txt = re.sub(r\"!\", \" ! \", txt)\n",
    "    txt = re.sub(r\"\\(\", \" ( \", txt)\n",
    "    txt = re.sub(r\"\\)\", \" ) \", txt)\n",
    "    txt = re.sub(r\"\\?\", \" ? \", txt)\n",
    "    txt = re.sub(r\"\\&\", \" & \", txt)\n",
    "    txt = re.sub(r\"\\%\", \" percent \", txt)\n",
    "    txt = txt.strip().lower()\n",
    "    return txt\n",
    "\n",
    "def remove_punctuation(txt):\n",
    "    '''\n",
    "    Removes punctuations in a given sentence.\n",
    "    :param txt: String, input sentence.\n",
    "    :return: a list of words from the input sentence without punctuation.\n",
    "    '''\n",
    "    return [w for w in txt if w not in string.punctuation]\n",
    "\n",
    "\n",
    "def remove_stopwords(txt):\n",
    "    '''\n",
    "    Removes english stopword in a given sentence.\n",
    "    :param txt: String, the input sentence.\n",
    "    :return: A list of words from the input sentence without any stopwords.\n",
    "    '''\n",
    "    return [w for w in txt if w not in stop_words]\n",
    "\n",
    "\n",
    "\n",
    "def fbeta(y_true, y_pred, threshold_shift=0, beta=1):\n",
    "    '''\n",
    "    Compute fbeta score.\n",
    "    :param y_true: y_true\n",
    "    :param y_pred: predicted value\n",
    "    :param threshold_shift: threshold\n",
    "    :param beta: beta value\n",
    "    :return: fbeta score\n",
    "    '''\n",
    "    \n",
    "    # just in case of hipster activation at the final layer\n",
    "    y_pred = K.clip(y_pred, 0, 1)\n",
    "    y_true = K.clip(y_true, 0, 1)\n",
    "    \n",
    "    # shifting the prediction threshold from .5 if needed\n",
    "    y_pred_bin = K.round(y_pred + threshold_shift)\n",
    "    \n",
    "    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n",
    "    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    beta_squared = beta ** 2\n",
    "    return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cosine_sim(u, v):\n",
    "    '''\n",
    "    Computes the cosine similarity between two vectors u and v.\n",
    "    :param u: Numpy ndarray, the vector u.\n",
    "    :param v: Numpy ndarray, the vector v.\n",
    "    :return: Float between 0 and 1, the cosine similarity score between the vector u and v.\n",
    "    '''\n",
    "    return np.dot(u,v) / (norm(u)*norm(v))\n",
    "\n",
    "\n",
    "def similarity(q1, q2):\n",
    "    '''\n",
    "    Computes the similarity score between lists of vectors.\n",
    "    :param q1: List of the first vector.\n",
    "    :param q2: List of the second vector.\n",
    "    :return: A list of similarity score between vectors in q1 and q2.\n",
    "    '''\n",
    "    sim = []\n",
    "    for el1, el2 in zip(q1, q2):\n",
    "        sim.append(cosine_sim(el1, el2))\n",
    "\n",
    "    return sim\n",
    "\n",
    "def save_result(filename, results):\n",
    "    '''\n",
    "    Saves a dictionary of data into a file.\n",
    "    :param filename: String, the filename\n",
    "    :param results: The dictionary to save into the file\n",
    "    '''\n",
    "    keys = results[0].keys()\n",
    "    with open(filename, 'w') as f:\n",
    "        dict_writer = csv.DictWriter(f,  keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(results)\n",
    "\n",
    "def make_accuracy(threshold_shift):\n",
    "    '''\n",
    "    Creates an accuracy function with a given threshold.\n",
    "    :param threshold_shift: Float, threshold\n",
    "    :return: An accuracy function\n",
    "    '''\n",
    "    def accuracy(y_true, y_pred):\n",
    "        '''\n",
    "        Compute accuracy score\n",
    "        :param y_true: actual output\n",
    "        :param y_pred: predicted output\n",
    "        :return: accuracy score\n",
    "        '''\n",
    "        y_pred = K.clip(y_pred, 0, 1)\n",
    "        y_pred = K.round(y_pred + threshold_shift)\n",
    "        return K.mean(K.equal(y_true, y_pred))\n",
    "    return accuracy\n",
    "    \n",
    "\n",
    "def make_fbeta(threshold_shift):\n",
    "    '''\n",
    "    Creates fbeta function with a given threshold.\n",
    "    :param threshold_shift: Float, threshold shift\n",
    "    :return: An fbeta function\n",
    "    '''\n",
    "    def fbeta(y_true, y_pred, beta=1):\n",
    "        '''\n",
    "        Computes the fbeta score.\n",
    "        :param y_true: y_true\n",
    "        :param y_pred: predicted value\n",
    "        :param beta: beta value.\n",
    "        :return: fbeta score.\n",
    "        '''\n",
    "        # just in case of hipster activation at the final layer\n",
    "        y_pred = K.clip(y_pred, 0, 1)\n",
    "        y_true = K.clip(y_true, 0, 1)\n",
    "        \n",
    "        # shifting the prediction threshold from .5 if needed\n",
    "        y_pred_bin = K.round(y_pred + threshold_shift)\n",
    "        \n",
    "        tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n",
    "        fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n",
    "        fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n",
    "        \n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        \n",
    "        beta_squared = beta ** 2\n",
    "        return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())\n",
    "    \n",
    "    return fbeta\n",
    "\n",
    "def get_w2v_vector(model, sentence, vector_size):\n",
    "    '''\n",
    "    Get the word2vec vector of a given sentence.\n",
    "    :param model: word2vec model\n",
    "    :param sentence: sentence\n",
    "    :param vector_size: vector size\n",
    "    :return: a word2vec vector of a given sentence\n",
    "    '''\n",
    "    sentence_len = len(sentence)\n",
    "    sentence2vec = np.zeros(shape=(sentence_len, vector_size), dtype='float32')\n",
    "    for i in range(sentence_len):\n",
    "        word = sentence[i]\n",
    "        word_vector = model[word]\n",
    "        sentence2vec[i] = word_vector\n",
    "    return sentence2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove all non-alphanumeric token in our corpus\n",
    "data['mr'] = data['mr'].apply(clean_str)\n",
    "data['ref'] = data['ref'].apply(clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mr</th>\n",
       "      <th>ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>name cocum   eattype coffee shop   food englis...</td>\n",
       "      <td>cocum cheap chinese coffee shop family friendl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>name the eagle   customer rating 5 out of 5   ...</td>\n",
       "      <td>eagle city centre near caf  brazil family frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>name cotto   eattype coffee shop   food englis...</td>\n",
       "      <td>area riverside near portland arms cotto high p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>name the wrestlers   eattype coffee shop   foo...</td>\n",
       "      <td>wrestlers family friendly venue near sorrento ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>name the punter   customer rating average   ar...</td>\n",
       "      <td>punter family friendly place riverside area hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                 mr  \\\n",
       "0      1  name cocum   eattype coffee shop   food englis...   \n",
       "1      0  name the eagle   customer rating 5 out of 5   ...   \n",
       "2      0  name cotto   eattype coffee shop   food englis...   \n",
       "3      1  name the wrestlers   eattype coffee shop   foo...   \n",
       "4      1  name the punter   customer rating average   ar...   \n",
       "\n",
       "                                                 ref  \n",
       "0  cocum cheap chinese coffee shop family friendl...  \n",
       "1  eagle city centre near caf  brazil family frie...  \n",
       "2  area riverside near portland arms cotto high p...  \n",
       "3  wrestlers family friendly venue near sorrento ...  \n",
       "4  punter family friendly place riverside area hi...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "elt = data.mr.append(data.ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr: name cocum   eattype coffee shop   food english   pricerange  20 25   customer rating high   familyfriendly yes\n",
      "ref: cocum cheap chinese coffee shop family friendly average customer rating\n",
      "is fake\n",
      "\n",
      "mr: name the eagle   customer rating 5 out of 5   area city centre   familyfriendly no   near caf  brazil\n",
      "ref: eagle city centre near caf  brazil family friendly rating 5 5\n",
      "is not fake\n",
      "\n",
      "mr: name cotto   eattype coffee shop   food english   pricerange high   customer rating 1 out of 5   area riverside   near the portland arms\n",
      "ref: area riverside near portland arms cotto high priced coffee shop english food 1 5 customer rating\n",
      "is not fake\n",
      "\n",
      "mr: name the wrestlers   eattype coffee shop   food english   pricerange more than  30   area riverside   familyfriendly yes   near raja indian cuisine\n",
      "ref: wrestlers family friendly venue near sorrento low customer ratings\n",
      "is fake\n",
      "\n",
      "mr: name the punter   customer rating average   area city centre   familyfriendly no\n",
      "ref: punter family friendly place riverside area high customer rating 5 5\n",
      "is fake\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"mr: {0}\".format(data['mr'][i]))\n",
    "    print(\"ref: {0}\".format(data['ref'][i]))\n",
    "    if data['label'][i] == 0:\n",
    "        print(\"is not fake\")\n",
    "    else:\n",
    "        print(\"is fake\")\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = data.groupby(['label'])[['mr']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mr\n",
       "label      \n",
       "0      4672\n",
       "1      4672"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    100.0\n",
       "1    100.0\n",
       "Name: mr, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['mr']/data.shape[0] * 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.countplot(x='label', data=data)\n",
    "plt.title('fake or genuine')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mr'] = data['mr'].apply(lambda x: x.split())\n",
    "data['ref'] = data['ref'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['mr_len'] = data['mr'].apply(len)\n",
    "data['ref_len'] = data['ref'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mr</th>\n",
       "      <th>ref</th>\n",
       "      <th>mr_len</th>\n",
       "      <th>ref_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[name, cocum, eattype, coffee, shop, food, eng...</td>\n",
       "      <td>[cocum, cheap, chinese, coffee, shop, family, ...</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[name, the, eagle, customer, rating, 5, out, o...</td>\n",
       "      <td>[eagle, city, centre, near, caf, brazil, famil...</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[name, cotto, eattype, coffee, shop, food, eng...</td>\n",
       "      <td>[area, riverside, near, portland, arms, cotto,...</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[name, the, wrestlers, eattype, coffee, shop, ...</td>\n",
       "      <td>[wrestlers, family, friendly, venue, near, sor...</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[name, the, punter, customer, rating, average,...</td>\n",
       "      <td>[punter, family, friendly, place, riverside, a...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                 mr  \\\n",
       "0      1  [name, cocum, eattype, coffee, shop, food, eng...   \n",
       "1      0  [name, the, eagle, customer, rating, 5, out, o...   \n",
       "2      0  [name, cotto, eattype, coffee, shop, food, eng...   \n",
       "3      1  [name, the, wrestlers, eattype, coffee, shop, ...   \n",
       "4      1  [name, the, punter, customer, rating, average,...   \n",
       "\n",
       "                                                 ref  mr_len  ref_len  \n",
       "0  [cocum, cheap, chinese, coffee, shop, family, ...      15       10  \n",
       "1  [eagle, city, centre, near, caf, brazil, famil...      17       11  \n",
       "2  [area, riverside, near, portland, arms, cotto,...      21       16  \n",
       "3  [wrestlers, family, friendly, venue, near, sor...      20        9  \n",
       "4  [punter, family, friendly, place, riverside, a...      11       11  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAFOCAYAAADZxVr8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xd4VGX6xvHvk4QkQAKh92KhK6I0BRsqxUJxsVBs2F356dpld3UVdW2ra0NXrIBi1xUQRLGASBEQEQFpSgfpnQSSPL8/ZnBjgDCBTM4kuT/XNVdmTnnnnkBOnrznPec1d0dEREREYlNc0AFERERE5MBUrImIiIjEMBVrIiIiIjFMxZqIiIhIDFOxJiIiIhLDVKyJiIiIxDAVa/IHZna6ma0I6L3vM7M3CrjNMWZ2eQG1dYqZzc/xeomZnVUQbYfbm2NmpxdUeyISfRbympltMrPv9rP+CjObGFC2183swSDeWwqWijUJREEUhWbmZrbDzLab2QYz+8LMLs65jbuf7e5DImzr6Ly2cfdv3L3R4WTO8X77HETdvZm7f10Q7YtIoTkZ6AjUdvc2QYUIsiiU6FOxVoKZWULQGQrAce6eAjQCXgeeM7N/FPSbFJPvlYjkQ4Q/9/WAJe6+I9p5pORSsVbEhU/F3WFmP4Z7mV4xs2rh03/bzGycmVUIb1s/3IN0lZktA76MoP2aZvaBma0zs1/N7KYc6+4zs3fNbGj4veaYWasc608ws5nhde+Z2Ttm9qCZlQXGADXDvWLbzaxmeLfEA7WXF3df7+7DgBuAAWZWKZzhazO7Ovz8aDMbb2ZbzGy9mb0TXj4h3MyscJaL9/b8mdldZrYGeO0AvYGtzWxu+BTIa2aWHG5zn79y9/bemdm1QF/gzvD7jQyv//20qpklmdlTZrYq/HjKzJLC6/Zmu83M1prZajPrF8n3SUTyFv45vMvMfgR2mFnCgY6DZnYV8DJwUvhn+f4I2m9sZp+b2UYzm29mF+VY97qZDTKzT8LHwKlmdlSO9Z3C+2wxs+fDx7OrzawJ8J8cOTbneMsKB2pPig4Va8VDT0Ld8A2BroQKob8CVQj9G9+Ua/vTgCZA57waNbM4YCQwC6gFnAn8xcxy7tcNeBtIA0YAz4X3TQQ+ItTbVRF4CzgfIPwX6NnAKndPCT9W5dVePnwMJAD7Ox3xAPAZUAGoDTwbznNqeP1x4SzvhF9XD2evB1x7gPfrS+j7eBSh7//fDxbQ3QcDbwKPhd+v6342+xtwItACOC78eXK2XR0oT+jf5Spg0N6iXEQOW2/gXELHoWwOcBx091eA64HJ4Z/lPHv1w3+ofg4MB6oCvYDnzaxpjs16AfcTOk4tAh4K71sZeB8YAFQC5gPtANx9Xq4caQdrT4oWFWvFw7Pu/pu7rwS+Aaa6+0x3TydUMB2fa/v73H2Hu+86SLutgSruPtDdd7v7L8BLhH7495ro7qPdPQsYRqiwgFChkQA84+573P1DYJ/Bt/txoPYi4u57gPWEiqzc9hAqvGq6e7q7H2x8RzbwD3fPyON79Zy7L3f3jYQOgr3zkzcPfYGB7r7W3dcROthemmP9nvD6Pe4+GthO6FSwiBy+Z8I/17uI7DgYqfMInTJ9zd0z3X0m8AFwYY5tPnL379w9k9AfdS3Cy88B5rj7h+F1zwBrInjPA7UnRYjG4RQPv+V4vms/r1Nybb88wnbrETpVmbNLPZ5QQbhXzoPFTiDZQuM8agIr3d3z+b77bS98oDkoMytFqEdx435W30mod+07M9sEPOHur+bR3LpwwZuXnJ9pKaHPXRBqhts7UNsbcn1PdrLvv7OIHJqcP9eRHAcjVQ9om6utBEJ/mO6V+xi49+e6Zs5c7u77GZaxPwdqT4oQFWslkx98EyB0YPjV3RscwnusBmqZmeUo2OoAi/OZIb+6A5nspxfP3dcA1wCY2cnAODOb4O6LDtBWJBnr5HheF9h7OncHUGbvCjOrns+2VxE6sM/ZT9siEl25/8g81ONgbsuB8e7e8RD2XU1o+AYQumVIztdE75gqMUCnQSUv3wHbwoNtS5tZvJkdY2atI9h3MpAF9A8P0O3OH8eR/QZUMrPyBRHUzCqaWV9gEPCou2/YzzYXmtneg9smQge37Bx5jjyEt77RzGqbWUVC48z2jnebBTQzsxbhiw7uy7Xfwd7vLeDvZlYlPFblXqBA70EnIhE5nONgbqOAhmZ2qZmVCj9ahy8QOJhPgGPNrEf47MWNhMau7vUbUDs8XliKGRVrckDhcWPnERrj8CuhsWAvExrYfrB9dwN/IjT4fTNwCaEDVUZ4/c+ECpJfzGyz/e9q0PyaZWbbCQ2cvRq4xd3vPcC2rYGp4e1HADeHx59AqJgaEs5y0QH235/hhC5a+IVQr+GDAO6+ABgIjAMWArnHx70CNA2/33/30+6DwHTgR2A28P3etkWk8BzOcXA/bW0DOhEa77aK0CnKR4GkCPZdT2hs22PABqApoWNERniTLwn1xK8xs/X5zSaxzf44pEgkesxsKvAfd38t6CwiIkVZ+Gr9FUBfd/8q6DwSXepZk6gxs9PMrHr4NOjlQHPg06BziYgURWbW2czSwvdc/CtgwJSAY0kh0AUGEk2NgHeBsoROE17g7quDjSQiUmSdRGjoRSIwF+gRwS2YpBjQaVARERGRGKbToCIiIiIxTMWaiIiISAwrNmPWKleu7PXr1w86hogUohkzZqx39ypB5ygIOoaJlCz5OX4Vm2Ktfv36TJ8+PegYIlKIzGzpwbcqGnQMEylZ8nP80mlQERERkRimYk1EREQkhqlYExEREYlhKtZEREREYpiKNREREZEYpmJNREREJIapWBMRERGJYSrWRERERGKYijURERGRGKZiTURERCSGqVgTERERiWFRnRvUzLoATwPxwMvu/kiu9dcDNwJZwHbgWnefG143ALgqvO4mdx8bzawiew2fumyfZX3a1g0giYiISBR71swsHhgEnA00BXqbWdNcmw1392PdvQXwGPBkeN+mQC+gGdAFeD7cnoiIiEiJEs3ToG2ARe7+i7vvBt4GuufcwN235nhZFvDw8+7A2+6e4e6/AovC7YmIiIiUKNE8DVoLWJ7j9Qqgbe6NzOxG4FYgETgjx75Tcu1bKzoxRURERGJX4BcYuPsgdz8KuAv4e372NbNrzWy6mU1ft25ddAKKiESJjmEiEoloFmsrgTo5XtcOLzuQt4Ee+dnX3Qe7eyt3b1WlSpXDjCsiUrh0DBORSESzWJsGNDCzI8wskdAFAyNybmBmDXK8PBdYGH4+AuhlZklmdgTQAPguillFREREYlLUxqy5e6aZ9QfGErp1x6vuPsfMBgLT3X0E0N/MzgL2AJuAy8P7zjGzd4G5QCZwo7tnRSuriIiISKyK6n3W3H00MDrXsntzPL85j30fAh6KXjoRERGR2Bf4BQYiIiIicmAq1kRERERimIo1ERERkRimYk1EREQkhqlYExEREYlhKtZEREREYpiKNREREZEYpmJNREREJIapWBMRERGJYSrWRERERGKYijURERGRGKZiTURERCSGqVgTERERiWEq1kRERERimIo1ERERkRimYk1EREQkhqlYExEREYlhKtZEREREYpiKNREREZEYpmJNREREJIapWBMRERGJYSrWRERERGKYijURERGRGKZiTURERCSGqVgTERERiWEq1kRERERimIo1ERERkRimYk1EREQkhqlYExEREYlhKtZEREREYpiKNREREZEYpmJNREREJIapWBMRERGJYVEt1sysi5nNN7NFZnb3ftbfamZzzexHM/vCzOrlWJdlZj+EHyOimVNEREQkViVEq2EziwcGAR2BFcA0Mxvh7nNzbDYTaOXuO83sBuAx4OLwul3u3iJa+URERESKgmj2rLUBFrn7L+6+G3gb6J5zA3f/yt13hl9OAWpHMY+IiIhIkRPNYq0WsDzH6xXhZQdyFTAmx+tkM5tuZlPMrEc0AoqIiIjEuqidBs0PM7sEaAWclmNxPXdfaWZHAl+a2Wx3X5xrv2uBawHq1q1baHlFRAqCjmEiEoloFmsrgTo5XtcOL/sDMzsL+Btwmrtn7F3u7ivDX38xs6+B44E/FGvuPhgYDNCqVSsv4PwihWr41GX7LOvTVr/AizMdw0QkEtE8DToNaGBmR5hZItAL+MNVnWZ2PPAi0M3d1+ZYXsHMksLPKwPtgZwXJoiIiIiUCFHrWXP3TDPrD4wF4oFX3X2OmQ0Eprv7COBxIAV4z8wAlrl7N6AJ8KKZZRMqKB/JdRWpiIiISIkQ1TFr7j4aGJ1r2b05np91gP0mAcdGM5uIiIhIUaAZDERERERimIo1ERERkRimYk1EREQkhqlYExEREYlhKtZEREREYpiKNREREZEYpmJNREREJIapWBMRERGJYSrWRERERGKYijURERGRGBbV6aZEBIZPXbbPsj5t6waQREREiiL1rImIiIjEMBVrIiIiIjFMxZqIiIhIDFOxJiIiIhLDVKyJiIiIxDAVayIiIiIxTMWaiIiISAxTsSYiIiISw1SsiYiIiMQwFWsiIiIiMUzFmoiIiEgMU7EmIiIiEsM0kbvIIdIE7SIiUhjUsyYiIiISww5arJlZfGEEEREREZF9RdKzttDMHjezplFPIyIiIiJ/EEmxdhywAHjZzKaY2bVmVi7KuURERESECIo1d9/m7i+5ezvgLuAfwGozG2JmR0c9oYiIiEgJFtGYNTPrZmYfAU8BTwBHAiOB0VHOJyIiIlKiRXLrjoXAV8Dj7j4px/L3zezU6MQSEREREYisWLvM3SfmXGBm7d39W3e/KUq5RERERITILjB4Zj/Lni3oICIiIiKyrwP2rJnZSUA7oIqZ3ZpjVTlA914TERERKQR59awlAimECrrUHI+twAWRNG5mXcxsvpktMrO797P+VjOba2Y/mtkXZlYvx7rLzWxh+HF5fj6UiIiISHFxwJ41dx8PjDez1919aX4bDs98MAjoCKwAppnZCHefm2OzmUArd99pZjcAjwEXm1lFQrcIaQU4MCO876b85hAREREpyvI6DfqUu/8FeM7MPPd6d+92kLbbAIvc/Zdwe28D3YHfizV3/yrH9lOAS8LPOwOfu/vG8L6fA12Atw76iURERESKkbyuBh0W/vqvQ2y7FrA8x+sVQNs8tr8KGJPHvrUOMYeIiIhIkZXXadAZ4a/j9y4zswpAHXf/sSBDmNklhE55npbP/a4FrgWoW7duQUYSEYk6HcNEJBKRzGDwtZmVC48j+x54ycyejKDtlUCdHK9rh5flbv8s4G9AN3fPyM++7j7Y3Vu5e6sqVapEEElEJHboGCYikYjkPmvl3X0r8CdgqLu3Bc6KYL9pQAMzO8LMEoFewIicG5jZ8cCLhAq1tTlWjQU6mVmFcG9ep/AyERERkRIlkmItwcxqABcBoyJt2N0zgf6Eiqx5wLvuPsfMBprZ3osTHid0e5D3zOwHMxsR3ncj8AChgm8aMHDvxQYiIiIiJUkk000NJFRwTXT3aWZ2JKH5Qg/K3UeTa7J3d783x/MD9tC5+6vAq5G8j4iIiEhxddBizd3fA97L8foXoGc0Q4mIiIhIyEGLNTOrAlwD1M+5vbtfGb1YIiIiIgKRnQb9GPgGGAdkRTeOiIiIiOQUSbFWxt3vinoSEREREdlHJFeDjjKzc6KeRERERET2EUmxdjOhgi3dzLaa2TYz2xrtYCIiIiIS2dWgqYURRERERET2Fcl0U2Zml5jZPeHXdcysTfSjiYiIiEgkp0GfB04C+oRfbwcGRS2RiIiIiPwukqtB27r7CWY2E8DdN4Xn+hQRERGRKIukZ22PmcUDDr/fJDc7qqlEREREBIisWHsG+AioamYPAROBf0Y1lYiIiIgAkV0N+qaZzQDOBAzo4e7zop5MRERERCKaG/RYoDGwFpinQk1ERESk8BywWDOz8oTmBa0D/EioV+1YM1sGdHd33RhXREREJMryGrP2ADAdaODu57t7D6AhMA14qDDCiYiIiJR0eZ0GPQto7u6/X/np7llm9ldgdtSTiYiIiEiePWu73T0z98LwsozoRRIRERGRvfLqWUs2s+MJjVXLyYCk6EUSERERkb3yKtZWA08eYN2aKGQRERERkVwOWKy5e4fCDCIiIiIi+4pkBgMRERERCYiKNREREZEYpmJNREREJIYdtFgzsw/N7FwzU2EnIiIiUsgiKcCeB/oAC83sETNrFOVMIiIiIhJ20Inc3X0cMC48V2jv8PPlwEvAG+6+J8oZRSSH4VOX7bOsT9u6ASQREZHCENGpTTOrBFwBXA3MBJ4GTgA+j1oyERERETl4z5qZfQQ0AoYBXd19dXjVO2Y2PZrhREREREq6gxZrwEvuPjrnAjNLcvcMd28VpVwiIiIiQmSnQR/cz7LJBR1ERERERPZ1wJ41M6sO1AJK55rQvRxQphCyiYiIiJR4eZ0G7UzoooLa/HFC923AX6OYSURERETCDnga1N2HhCdzv8LdO+R4dHP3DyNp3My6mNl8M1tkZnfvZ/2pZva9mWWa2QW51mWZ2Q/hx4h8fzIRERGRYiCv06CXuPsbQH0zuzX3end/cj+75dw/HhgEdARWANPMbIS7z82x2TJCvXe376eJXe7e4uAfQURERKT4yus0aNnw15RDbLsNsMjdfwEws7eB7sDvxZq7Lwmvyz7E9xAREREp1g5YrLn7i+Gv9x9i27WA5TlerwDa5mP/5PB93DKBR9z9v4eYQ0RERKTIyus06DN57ejuNxV8nD+o5+4rzexI4Eszm+3ui3NuYGbXAtcC1K2r6XZEpGjRMUxEIpHXadAZh9n2SqBOjte1w8si4u4rw19/MbOvgeOBxbm2GQwMBmjVqpUfZl4RkUKlY5iIRCKv06BDDrPtaUADMzuCUJHWC+gTyY5mVgHY6e4ZZlYZaA88dph5RERERIqcvE6DPuXufzGzkcA+f/G5e7e8Gnb3TDPrD4wF4oFX3X2OmQ0Eprv7CDNrDXwEVAC6mtn97t4MaAK8GL7wII7QmLW5B3grERERkWIrr9Ogw8Jf/3WojYfnFB2da9m9OZ5PI3R6NPd+k4BjD/V9RURERIqLvE6Dzgh/HW9miUBjQj1s8919dyHlEykww6cu22dZn7Ya1C0iIrEtr541AMzsXOA/hAb3G3CEmV3n7mOiHU5ERESkpDtosQY8AXRw90UAZnYU8AmgYk1EREQkyiIp1rbtLdTCfiE0mbuIiEiRkXsohIZBSFGR19Wgfwo/nW5mo4F3CY1Zu5DQbTlEREREJMry6lnrmuP5b8Bp4efrgNJRSyQiIiIiv8vratB+hRlERERERPYVydWgycBVQDMgee9yd78yirlERETyRWPSpLiKi2CbYUB1oDMwntBNbHWBgYiIiEghiKRYO9rd7wF2hOcLPRdoG91YIiIiIgKRFWt7wl83m9kxQHmgavQiiYiIiMhekdxnbbCZVQDuAUYAKeHnIiIiIhJlBy3W3P3l8NPxwJHRjSMiIiIiOUVyNWgl4D6gPaGb4n4DPODuG6IbTUoSTbIuIiKyf5GMWXsbWAv0BC4A1gPvRDOUiIiIiIREMmathrs/kOP1g2Z2cbQCiYiIiMj/RNKz9pmZ9TKzuPDjImBstIOJBC3bs4OOICIikudE7tsIjVEz4C/AG+FVccB24PaopxMJyJTVo/jP7FsBKFuqPBmJj9DveM3AJiIihS+vuUFTCzOISKzYnLGWV+f+lZplj+LYyqcyf9N3XD3yaqqlVOOcBucEHU9EREqYSMasYWbdgFPDL79291HRiyQSrNfn3svurHT6H/csNVOOJj1zB4PmXMJF713EN/2+4fgaxwcdUURESpBIbt3xCNAaeDO86GYza+/uA6KaTCQA7899n2m/jaFXw7upmXI0AMkJZRnVexQnvnIi579zPj/9+SdSElMCTioi+7vlj0hxFMkFBucAHd39VXd/FehCaH5QkWLn4YkPUzulEefUv+YPy2uk1mD4n4azbMsy/vbF3wJKJyIiJVFEp0GBNGBj+Hn5KGURCdSvm37l+9Xf06fRX4mP2/dHo33d9tzY+kae/e5Zeh3TC6hV+CFFpMDk7pnTjbglVkXSs/YwMNPMXjezIcAM4KHoxhIpfB/O+xCA1tXOPuA2/zzzn9QuV5urR17NnuyMwoomIiIlWJ7FmpkZMBE4EfgQ+AA4yd01g4EUOx/M+4Djqx9P1TIH/us6NSmVwV0HM3fdXN6Z/2ghphMRkZIqz2LN3R0Y7e6r3X1E+LGmkLKJFJqVW1cyecVkejbpedBtuxzdhf6t+zNm6SvMWvd19MOJiEiJFslp0O/NrHXUk4gE6KOfPwKgZ9ODF2sAj3V8jNopjXhx9u1syViX7/dzd9buWMs3S79h0vJJbN+9Pd9tiIhIyRDJBQZtgUvMbAmwg9CMBu7uzaMZTKQwfTDvA5pWaUrjyo35fvHBbwdQulRp+h/3LPdM7so/p/VlQOs3SEuqmuc+2Z7FvI1TmLLmE2755nPW7lj7+zrDqFeuKVc3e5Qjyh972J9HRESKj0iKtc5RTyESoM3pm5mwdAJ/Pfmv+dqvTmojbm/5Kk9+fw0Dp17IgFZvAPuOd9u2exMTVr7LuGVvsHbXMpLiy9CjcVdOqn0SjSo3IjM7k5mrZ/LUlBe4f2pP+jV9kNNqX1RAn05ERIq6vOYGTQauB44GZgOvuHtmYQUTKSwTl00k27M588gz873vMZVOZkCrN3hsxhXcMfFMZm7pRa9jepHt2azetpqP53/M6IWfkuV7aFShDRc2uJ2W1TrRr12jP7RzXsPzqBJ3HoNm3cTgn+4gI2sXnepdXlAfUUREirC8etaGAHuAb4CzgabAzYURSqQwjV8ynsT4RNrWantI+zeo0JIHThrB6CUv88G8Dxgya8jv62qm1qRzvSs4pVZP6qY2ybOdcomVuKvVUP4140reXvAwLap0YH89dSIiUrLkVaw1dfdjAczsFeC7wokkUrgmLJtAm1ptKF2q9CG3Ub3sEVzZ7CE+6vs8U1dOJTUxlYqlK3JkhSN5Z9rKiNuJs3iuavYwd048i1fmDODm0ycQuoOOiIiUVHldDbpn7xOd/pTialvGNmasmsFp9U4rkPZSk1I568izaFu7LQ0qNSA+Lj7fbVQqXZPejQbw04aJvPbDawWSS0REiq68irXjzGxr+LENaL73uZltLayAItE0afkksjyrwIq1gnJGnb40SGvJPV/dw+6s3UHHERGRAB2wWHP3eHcvF36kuntCjuflImnczLqY2XwzW2Rmd+9n/alm9r2ZZZrZBbnWXW5mC8MPjbSWqBi/dDwJcQm0q9Mu6Ch/EGdx9Djq/1i1bRXv/KQJQ0SGT122z0OkpIjkpriHxMzigUH87+KE3mbWNNdmy4ArgOG59q0I/IPQPd7aAP8wswrRyiol1/il42lZoyVlE8sGHWUfx1U+naZVmvLklCcJTSYiIvmVng5ffgljx4J+jKSoilqxRqjIWuTuv7j7buBtoHvODdx9ibv/CGTn2rcz8Lm7b3T3TcDnQJcoZpUSKCNrF9NWTou5U6B7mRm3nngrP6z5ga+WfBV0HJEiJSPduPRSqFABzjwTunSBx26pwrrV+R9HKhK0aBZrtYDlOV6vCC+L9r4iEVm0+Xv2ZO/htPqxWawB9G3el6plq/Lk5CeDjiJSZOzYZjx6cxXefBOuvBJGjoRnnoH5s5K4u28Nfv25VNARRfIlmsVa1JnZtWY23cymr1uX//kZpWSbv2k6hsXceLWckhOSubH1jXyy8BMWb1wcdBwpYDqGFbwd24yHbqzGojlJvPMODBoE550H//d/8Ojw1SQlO0OeqKhTolKkRLNYWwnUyfG6dnhZge3r7oPdvZW7t6pSpcohB5WSacGm6RxT9RjSktOCjpKnK4+/EsMYOmto0FGkgOkYVvCGPFGR5YtLcdvj67jwwj+uq1Iji4v/vJmFs5OYNLZMMAFFDkE0i7VpQAMzO8LMEoFewIgI9x0LdDKzCuELCzqFl4kUiGzPYuHm72lfp33QUQ6qdrnadDyqI0N/HEq25x7eKSJ7Tf2yNN9+WpYeV2zluJPS97vNKefs4MgmGbw1KI30nbrhtBQNUSvWwjfS7U+oyJoHvOvuc8xsoJl1AzCz1ma2ArgQeNHM5oT33Qg8QKjgmwYMDC8TKRDLt80nPWs77evGfrEGcPlxl7Nk8xImLJ0QdBSRmLRpfRyvPlqRI5tk0L3flgNuFxcHl926iU3rEvjkzYjuQiUSuLymmzps7j4aGJ1r2b05nk8jdIpzf/u+CrwazXxSci3YPB2gSPSsAfRo3INySeV4/YfX6VRjYNBxRApc7vum9Wmbv3lxhzxRkYx044Z/bCDhIL/ZGhy7m5an7uSz91PoeulWEpM1gE1iW5G+wEDkUC3YNJ20pKrUT6sfdJSIlClVhouaXsT7c98nPXNH0HFEYsoPk5KZ9lUZzu+3lZr1I5sdsfPF29i+JZ5Jn2vsmsQ+FWtSIi3YNIOGaa2K1CTpV7S4gh17dvDdb2OCjiISM3anG0OeqECNens4p0/kMyE2PSGDOkftZuy7qb9fGapZEiRWqViTEmdj+hrWp6+gYYVWQUfJl3Z12nFE2hFMXh3pdToixd+IYeVYu7IU/e7YSKnEyPczg84XbWPZwkR+npkUvYAiBSCqY9ak6NnfX5L5HTsS6xZsCo1XK2rFmpnR+5jePPLto2zJWE/5pMpBRxIJ1LpV8YwaVo6TOu2gWauMfO/fvvNO3h6UxqfvpNLkhPzvL1JY1LMmJc6CzdNJii9NvdTcU9XGvj7H9iHbs5i65pOgo4gE7p0X0jBzet+4+ZD2T0x2OnTfzoxvSrNpvX4dSuxSz5oUefntDfx541SOKt+ChLiiN+VMs6rNqJPSmEmrP6ZTvcsLpM2S0Jsqxc/C2YlM/rws51+5hUrVsg65ndO67mDksPJMHFOWrpduK8CEIgVHxZqUKDv2bGHZtnn86ehbgo5yyNrV7M47Cx5l3c7lVClT54DbqQiT4io7G4Y9VYG0ypmcd0nkFxXsT426mTRsns4nW6eGAAAgAElEQVT4USmcd8k2itA1R1KCqN9XSpSfN32H4zSp2DboKIfspOpdAZi8ZmTASUSC8e3YMiyek8SF120huczh3yPttPN2sHppKRb9lI8rFEQKkYo1KVHmbZxCqbgkjirfIugoh6xKmTo0SGvJpFUfBx1FpNDt3G689WwFjmqawannFsw9B9ueuZOk5GzGj0opkPZECpqKNSlR5m2cwtHljycxPjnoKIelXY1uLN/+Myu2Lwg6ikih+vDl8mzdFMcVd2wiroB+g5Uu67Q5YyeTPy9DRrrOg0rsUbEmJcaOPVtYunUuTSqeGHSUw9am+jkYcUxZrVOhUnIsX1yKse+l0qH7do5ssrtA2z7tvB2k74zjuy81o4HEHhVrUmLM3zQdJ7tYFGtpSVVpWukkJq8eibvmNZTiLysTXnqoImXKZnPRDQeeqP1QNT4+g2q19zB+VNkCb1vkcKlYkxJj3sbJJFgiR6cdH3SUAnFS9a6s2fkrS7b+FHQUkagb9WY5Fs9N4oo7NpFaPrvA2zcL9a7N+z6Z31Yc+EYJmo5KgqBiTUqMnzdO5ei0oj9eba/W1c4m3hJ0VagUe7NnwwcvlaftmTs48aydUXufk8/ZgcW5etck5qhYkxJh065N/Lr1p2JxCnSvlMQ0jq18KlNWjyTbC76nQaQgHWqPVEYGXHYZlE3Npt8dm6J6H7RKVbNo3jadCZ+UJfvQ77MrUuBUrEmJMHbxWJxsjqt8WtBRCtRJNbqyIX0Vk5ZPCjqKSFQMGAA//ADX/HUjqWnR/6Pk9K7b2bQugR+nFo8eeCkeNIOBRFWs3EX/k4WfkFqqIkelFd37q+1Py6qdSIxL5q3Zb3Fy3ZODjiMSsUh618aMgX//G/r3hxNO2VUIqULvk5qWxRcfpdCiXXqhvKfIwahnTYq9rOwsPl30Kc2rnEacxQcdp0CVTkjh+Kpn8d7c99iTtSfoOCIFZu1auOIKOPZYePzxwnvfhFJwRo/tzJxYOs8LDUQKk4o1KfamrZrG+p3raVG5Q9BRoqJdjW6s27mOL379IugoIgXCHW64ATZvhrfeguRCPiPZsed24uLgs/c0o4HEBhVrUuyNXjiaOIujeTEbr7bXcVVOp3xSed766a2go4gUiCnjyvDhhzBwIDRrVvjvX6FKFieetZOvR6aw9fDmiRcpECrWpNj7ZOEnnFT7JFIS04KOEhWl4pLo2aQnH837iF17Cmdcj0i0bNkQx+v/qkCbNnDbbcHl6NJrG+k743j11eAyiOylYk2KtdXbVvP96u85t8G5QUeJqt7H9mbb7m18svCToKOIHJY3n61Axq44Xn8dEgIcMnZkk900Oi6dp5+GzMzgcoiAijUp5v77838BOLdh8S7WOtTvQM3UmgydNTToKCKHbPGcRL79tCxn995KkyZBp4Fz+25jyZLQuDmRIKlYk2Jt2I/DOKbqMRxb9digo0RVfFw8fY/ty5hFY1i7Y23QcUTyzR2GPVWB8hWz6HZZbAwUO/7kXTRvDg89BFm6Sa4ESMWaFFsLNyxk8orJXNb8Miyatz2PEZcfdzmZ2Zm8NVvdAFL0TBlXhoWzk7jwus2ULutBxwEgLg7+9jeYPx8++CDoNFKS6SYyUmwN+3EYcRZH3+Z9g45SKJpVbUbLGi0ZMmsIN594c9BxpAQ53Jtf79phvPVcGnUb7Oa083YUZLTD1rMnNG4MDz4IF1wQdBopqdSzJsVStmcz7MdhnHXkWdRMrRl0nEJz2XGXMXPNTGb/NjvoKCIRe/eFNDaujefKOzcSF2P3rY6Ph7/+NTSZ/KhRQaeRkkrFmhRLE5dNZMnmJVzW/LKgoxSq3sf0JiEugSGzhgQdRSQiC35M5PMPUuh4wXYaHLs76Dj71bs31K8PjzwSGlsnUthUrEmx9MrMV0hJTKFH4x5BRylUVcpWoWvDrgyZNYTdWZrXUGJb+k7jpX9WomK1LC6+YXPQcQ4oIQFuvx0mT4aff0gKOo6UQCrWpNhZs2MJb/74JlcdfxVlE8sGHafQ9W/Tn/U71zN59cigo4gc0PYtcTx8U1VWL0vg6gEbSS4T211W/fpBlSowcmi5oKNICaRiTYqdDxc/RWJ8IneffHfQUQLRoX4HmlZpymfLXsd1zkZi0KqlCTxwQ1WWLkjkL4+sp3nb2O8FLlMGbr4ZZk0uzdKFpYKOIyWMijUpVlZuX8ikVf+lf5v+VE+pHnScQJgZ/Vv3Z8nWn1i0+fug44gAobFeP32XxOO3VuGOi2uyfk0Cd/x7La1OLTpTpP35z5BcJpsxb6UGHUVKGBVrUqx8sOgpkuLLcGf7O4OOEqhLj7uU0gmpjF32etBRRPjqKxh4XVUevqkav/6cyJ+u3syT762iWcuMoKPlS4UK0K7zDqZ+UYYd24r/vRsldkS1WDOzLmY238wWmdk+56TMLMnM3gmvn2pm9cPL65vZLjP7Ifz4TzRzxqLhU5ft8yhJ3J3dWbvZtWcXWdmR3Tp8wsr3mbpmFGfXv4rKZSpHOWFsS0lM4bRaF/LdmtGs27k86DhSgj32GJxxBqxbncAVt2/k6f+upOfVWylfKTvoaIfkjO7b2Z0Rx7djS954WAlO1Io1M4sHBgFnA02B3mbWNNdmVwGb3P1o4N/AoznWLXb3FuHH9dHKKbHF3Zm8eiT9v25D0oNJlPlnGao/UZ07P7+TxRsXH3C/eRun8PJPd9OsUnt6HHVTISaOXecccS1xFs8Hi/4ddBQpgdzh3nvhrrugVy948v1VdLxgO6USg052eI5ovIf6DXfz1ccpuo2HFJpo9qy1ARa5+y/uvht4G+iea5vuwN4bQr0PnGklYV4g2a/tuzfzr++v5LlZ/amQVI0HOzzII2c+wqn1TuXJyU/S4NkG9Hy3J9+t/O73fTKzM5m8eiRPzbyOamXqcnOLF0iI0+BfgErJNehU7womrvqQ5dvmBx1HSpiHHoIHHoArr4Q33oDEYnTHiw7dt7NsYSK//lzEK08pMqI53VQtIOf5lxVA2wNt4+6ZZrYFqBRed4SZzQS2An9392+imFUClpm9h2d+uIH5m6ZzSeN76VzvCi458Yjf16/cupLnpz3P89Of58N5H1I9pToNKzXk102/snzrcmqUPYrbW75G2VLlA/wUsafbEX/mq+Vv8e6Cx7it5StBx5Fi4mDDMqZPKM2/74FLL4WXXgrNsVmctOu8g+HPpvHVx2U5sskfvxf5mWZLJFKx+iO0Gqjr7scDtwLDzWyfm9uY2bVmNt3Mpq9bt67QQ0rBefPnB5mzcRJXHfMwZ9e/ijj745wztcrV4qEzH2LZX5bx3NnPcfbRZ5OZnUnTKk257YRXeOzkcVQrUy+g9LErJTGN8464nu/XjWPuhslBx5FciuMxbMWvCbxwXyVat4bBg4tfoQZQJsVpe+ZOJn1Wlox0nQyS6Itmz9pKoE6O17XDy/a3zQozSwDKAxs8dHOoDAB3n2Fmi4GGwPScO7v7YGAwQKtWrTR6oIh6/YfX+WzZ65xd/2pOrZX3TMmpSanc2ObGPywraRdf5FeX+lcyfuU7/Gf2rdzaoSMVS1c8pHYOd7Ju2VdxO4al7zKeursKScnOhx9CcnLQiaLn1HN3MOGTFKZ/XZr2XXYGHUeKuWj+zTMNaGBmR5hZItALGJFrmxHA5eHnFwBfurubWZXwBQqY2ZFAA+CXKGaVgKzetpqbP72ZJhVPpHfDAUHHKZaS4kvT/7jn2Jyxjn4f99ONciVq3nwmjTXLErjxgfXUrh10muhq1CKDKjUymTBaV4VK9EWtWHP3TKA/MBaYB7zr7nPMbKCZdQtv9gpQycwWETrduff2HqcCP5rZD4QuPLje3TdGK6sE55axt5CRmcHVzR4hPi6aHb0l25Hlm9O70QBGzB/BE5OfCDqOFEMzJpTmy49SOafPtiJ3/7RDERcHJ5+zgznTktmwNv7gO4gchqj+dnT30cDoXMvuzfE8HbhwP/t9AHwQzWzFRVE+NTV20VjemfMO9512H9VLH3HwHeSwdKl3JTvtJ+74/A52Z+1mwMkD0MXXUhC2bIjj5YcrUq/hbi68LnYnZC9op5y9g49eKc+3n5al22Vbg44jxZi6MkqIWCvqMjIzuHH0jTSs1JC7T76bD2b8FliWksLMeLvn2/T7uB9/+/Jv/Lb9Nx7v9HjQsaSIc4eXH6nIrh1x/O3534r8fdTyo1rtTBodl843n5Sl66Vb0d8+Ei3F8DodKQqen/Y8izct5pkuz5CUUIxuwBTjSsWXYuj5Q7nlxFt45rtnOOHFE1i4aUbQsaQI+2Z0Wb7/pgwXXb+Z2kdkBh2n0J1yzg5WLS3FojklqEqVQqdiTQrdxl0beWDCA3Q+qjOdj+4cdJwSJ87ieLLzk3zS5xO2Zmzl/qk9eemnO9mcsTboaFLErF8Tz9AnK9CoRTpdLt4WdJxAnHjWTpLLZPPlRylBR5FiTMWaFLqHJjzE5vTNPNbxsaCjlGjnNDiHuTfO5ez6V/PNyg+5bcLpjFnyCtleNOdslMKVnQ2DH6xEdjZcf88G4kroGPvSZZ12nXcweVwZdmzVeVCJDo1Zk0K1ducynpv2HP1a9KN5teZBxynxUhJT6Nv475xZpy/Dfr6fN34eyA/rvqRD07epVa5W0PEkRuxvzOvn76cwZ3oyV929gaq1sgJIFTvO7LGdLz9K5ZsxKVzTMeg0UhypZ00K1XsL/0W8xTOww8Cgo0gO1csewe0nvMZVzR5h4eYZtHixBTNWaSyb7N+qJQm8NSiNFu120aH7jqDjBK5+oz0c1SyDLz7U5O4SHSrWpNAs2foTk1Z/zF9O/It6bWKQmXFGnd48eNInlC1VljOGnsG3y74NOpbEmOws+M8DlUhKcq7+6wZdARl25vnbWbW0FBMmBJ1EiiMVa1Jo3lnwGCml0riz/Z1BR5E81Ew5im/6fUO1stXo9EYnJi2fFHQkiSFj301l8ZwkLrttExUqa3zjXieetZOy5bJ4+umgk0hxpGJNCsWcDd/y4/rxdDvyRtKS04KOIwdRp3wdJvSbQM3UmvR4uwdLNy8NOpLEgLUr43nvxfK0aL+Ldp00H2ZOScnOWX/azn//Cz//HHQaKW5UrMnvxi4ay7B59zNw6gUMnHoB09aMKZArA7M9m+Hz/0ml5Jp0rHtZASSVwlA9pToje49kd9Zuur3djfRMjU0qydzhlUcqYnFw5Z0bdfpzP7pcvI1Sidlcf+d2hk9dtt8LM0QOhYo1YVvGNq747xV0ebMLXy4fTrZnsTljLU/9cD0Dvu3Cgg0LDqv9b1d9xJKtP3FxwztJjE8uoNRSGBpXbsy7F77LT2t/4j+zb9Mk8CXY1C/K8NO00vT682YqVSvZV38eSLkK2ZzedQcTx5TVfKFSoFSslXDz1s3j+BePZ9iPw7jn1Ht46azZ3HfiRzx+8pf8ufnTbN29no7DOrJi64pDaj8jaxfvLHiMI8s156Qa3Qs4vRSGTkd14uEzH2bab2P4asVbQceRAOzOgLcHpVG3wW7OPH970HFi2jl9tuIOY95KDTqKFCMq1kqw6aumc8prp7B993a+vvxrBnYYSEJcaMqU+LgE2tfswV2thrI5fTOdhnVi/c71+X6P0UteYlPGGvo2voc403+3our2drdzTKVTGDrvPlZsO7yeVil6Pn2nHOtWJ3DJzZtK7M1vI1WlZhbtOu3ky49S2LRO3ywpGPrtWUL9tGEiHYZ0IDUplYlXTuSUeqfsd7v65Y5hZO+R/Lr5V3q+25PM7Mjn/luyeQkjf3mBVtU607him4KKLgGIszhuaP4kpRNSeG7W/7EnOyPoSFJI1qyBj18vxwmn7KRZK/27R6LnNZvJyjLeH1w+6ChSTKhYK4EmrHyfx6ZfTr3y9ZjYbyJHVzw6z+1PrXcqL3V9iQlLJ3DPl/dE9B7uzjUjr8EwLm38j4KILQFLS6rKdcf+i+Xbf+bDRbo/QUnx8MOwJ8Po83+bg45SZFStmUXHC7YxflRZfvwx6DRSHKhYK0Eys/fw7oLHeHH2bTSu2JZvr/w24pvTXtL8Eq494Voe+fYRRi0YddDtX/vhNcb9Mo7ejQZQubRugFtctKhyBqfVupCRv7zA4i2zgo4jUbZuHbz0ErTvsoMadSPvVRfoccVWyqRmc6duKykFQMVaCfHrltncM7krH/8yiNNrX8ydLV+nfHL+uuifPvtpWlRvwSUfXsKsNQf+Rb1k8xJuHXsrp9Y7lTPq9D3c6BJj+ja+h7Skqrw4+zbSM9ODjiNR9PTTkJ4OXS/dGnSUIielfDbn99vK2LEw6uB/34rkSRO5FwHrdq1g/qbvWDUpk/U715OSmELF0hWpmVqTJVuTqFK6NmUSymG5bny0OX0z434ZxyszX2HsorGUT6rCLccPplW1zoeUIzkhmY97fUz7V9vT+Y3OTLxy31OoK7au4IwhZ2BmvNz1ZaYt0t8DxU3ZUuW55phHeWzG5Tw04SEeOOOBoCNJFGzZAs89B3/6E9Ssr161Q9Hxgm3MHFeBG2+E00+HlJSgE0lRpWIthk3/7TM+W/oaczb+b7qfhLiE/Q7yT4ovTVpSVUrFJfHozGTWbF/D2h1rAahdrjbdj+rPOfWvoWypwxvwWrd8XT675DNOee0UOg7ryMtdX+aMI0LF2eKNizn7zbPZsGsD4y4dR4NKDZi2SDeFLI6Oq3I67Wuez6PfPkrvY3vTtErToCNJAXvhhVDBNmAAzFetdkgSSsGLL8LJJ8M//gFPPBF0IimqVKzFoO27tzN49u2MX/keVUrXoefRt9K6WhduOKUtqYmp7Mnew8ZdG1m5dSXDpk1j/a6VbMxYw+aMtWRm76FGWila12xNo0qNOL7G8XSo34F3pq0ssHxNqjRhTN8xdH+7O2cNO4uWNVriON+v/p6ypcry2aWf0bpW6wJ7P4lNlzS+h3mbxnPtyGuZ0G+Cbs1SjKSnw1NPQadO0LIlzJ8adKKiq317uO660PezT5/Q91Mkv1SsxZilm5fS+Y3OLNiwgPOPuonzj7qZ+LjQP1O5pHIAJMYnUj2lOtVTqjO/epV92ujTtm7Ucy5cUY1/nvQ1E1d9yNilr1M6IYVHz3qUi5pdRP20+lF/fwleucRKPNHpCfp93I+Xv3+Za1teG3QkKSDDhsFvv8FddwWdpHh45BEYMQIuvxxuH7ScxOQ/zgRSGMdsKdpUrMWQFVtXcMbQM9i4ayMDWg+nWaV2QUfKU2J8MmfU6cMZdfoAOuCURJcfdzlDZw3l7nF306NxD6qWrRp0JDlM2dnwr3/BCSdAhw5Bpyke0tLgtdegSxd4+/k0Lrt1U9CRpIjReYsYsWb7Gs4ceibrdqzjs0s+i/lCTQTAzBh0ziC2797OnZ/rHgXFwYgRsGAB3Hknmqy9AHXuDDffDGPfTeWHSZojWfJHxVoM2L57O+cOP5eVW1cypu8YjfeSIqVJlSbc3u52hswawoSlE4KOI4fpscegfn3o2TPoJMXPI49A7aN28+IDlTTRu+SLToMWkOFT973qMZLTglnZWfT+oDc/rPmBkb1H0r5u+2jEE4mqv5/6d4bPHs4Nn9zAzOtmkhifGHQkyYe9x6+fvkti8uRqPPssJOi3Q4FLToabHlzPvVdV5+kBlbnnhd8opR8ViYB61gLk7tz86c2MWjCK585+jnManBN0JJFDUqZUGZ475znmrpvL498+HnQcOQTZ2fDWoApUrp7JNdcEnab4qnVEJtffs4HFc5IY+mSFoONIEaFiLUD3fX0fg6YN4raTbuOG1jcEHUfksJzX8DwubHohD0x4gAUbFgQdR/Jp6hdlWDI/kQuu20xSUtBpirfWHXbR9bItfPnfVMa8lRp0HCkCVKwF5KkpTzFwwkD6tejH4x3VEyHFwzNnP0NyQjLXjboOdz/4DhITMvfAu/8pT90Gu2nfeWfQcUqEi67bQusOO3nj6QoMHx50Gol1KtYKWbZnc+9X93LL2Fvo2aQng7sO3meaKJGiqnpKdR7v+DhfL/maF6a/EHQcidCYt1NZu7IUvf68mTj9VigUcfHw5/vW0+SEdK64AkaODDqRxDL9WBaizembOf+d83lgwgNcdfxVDO85nIQ4jeKV4uWqE66iy9FduHXsrcz+bXbQceQgZs2C9wen0eq0nTQ/MT3oOCVKYhLc+tg66hydQfcezmW3buLNKZqiT/alYq0QbM3YyoMTHuSIp49g1IJPuLzJ/XSoeg/vT1+z36tIRYqyOIvj9e6vk5acRu8PerNzj06rxar0dOjbF1LKZXP1gI26r1oAyqQ4f3t+LS1P2cWwf1fgpYcqskn3zJVc1K1TgNydLbvXsXbnMtbuWsa8Lzcwful4pqyYwp7sPXRt2JUTK19P/XLHBB1VJKqqpVRj6PlD6fxGZ64fdT2v93hdc4fGGHe49VaYMwfu/PcGUtOyg45UYiWXdm5+eD3vDy7PiKHlaNgQHn4YrrhCt1CREP03OAxbM7by6aJPmbhsIqN+/ppVOxaRkbXr9/WG0bJmS2458RYubHYhrWq2Uk+alBidjurE/affzz++/geVSlfiyc5PanxmjHCHu++GF16A226D407S6c+gxcXBRddvoc0ZOxn9Yg2uuQb++U+44w4o3fSP84lqar+SR8VaPu3J2sPIBSMZOmsony76lIysDMqWKku91OZ0qN2HamXqUrVMXaqWrkv/09qRnKBpRaTkuufUe9i4ayNPTX2K1KRU7j/9fhVsAcvODhVqjz8ON9wQmrHg7WlBp5K96jfcwzffhKb9evhh+POfoVyFmnS6cBtn/Wm7ekBLqKgWa2bWBXgaiAdedvdHcq1PAoYCLYENwMXuviS8bgBwFZAF3OTuY6OZ9WAWbVzEqzNf5bUfXmPN9jXUSq3FDa1u4MJmF9KmVhvenbZqn31UqElJZ2Y82flJtmVs44EJDzDrt1m80u0VKpepHHS0Eunnn+Hqq+Hbb+GsP22j3aWbVKjFIDPo3h26dYPx4+GWv+3m/cFpfPx6edqcsZNad0O7dlCqVNBJpbBErVgzs3hgENARWAFMM7MR7j43x2ZXAZvc/Wgz6wU8ClxsZk2BXkAzoCYwzswauntWtPLuz+ptq/no5494d867jF86njiL49wG53Jdy+vocnQX4uM0t5vIwcRZHC91e4ljqx3LXePuovkLzfn7qX/nsuMuIyUxJeh4xZ47zJgBgwfDkCGQkgLX37uBk8/eoQsKYpwZnH463PHkOlb8UopxH6YwcUxZTv8UypSBE0+Eo4+G3zK2ULZcNolJTnIZp0e7SlSvDnXrQloa+ncuBqLZs9YGWOTuvwCY2dtAdyBnsdYduC/8/H3gOQudI+kOvO3uGcCvZrYo3N7kgg6Z7dlsSd/C+p3r+XXzryzeuJiZa2Yyafkk5q6bi+M0qtSIh854iMuPu5xa5WoVdASRYi/O4vjLiX/h9Pqnc92o67hx9I0M+GIA3Rp146TaJ3FCjROoXa421cpWo1S8ugsOhTvs3Anr1sGvv8LChTBlCkycGHpeujRcdhk8+CB8sWRH0HEln2ofuYcrbt9Erxs3M2tyMvN/SGbBj4nM+CGBbVvKkZ31v4rsPzn2K1cuVLTVrAnVq0PFilChQmh5aur/Hikpof8jpUuHLmqIjw+No9tb6MXHh5YnJYW2SU4m3/fkcw+dhs/ODj03Cz3i41VQHkw0i7VawPIcr1cAbQ+0jbtnmtkWoFJ4+ZRc+xZYldTtrW5MWj6J9Mx0du7ZifPHO62nJadxUu2T6HNsH3o07kHTKk0L6q1FSrQW1Vsw9eqpTF0xleemPce4X8bxxo9v/L7eMD68+EN6NO4RYMrY9uabcO+9oV94WVmwZw9kZMD27aHnOVWsCPWb7uSK7um077KDMinOF0sCiS0FJLm00/aMXbQ9438Xs2VnQ8YuY3e6sWtHHG1r1mT1ali2DJYsCX39aWEGM2bFs2NbHOk7C+bK7OTk0KNUqdBjb/HmDpmZoceePf97ZGYeuK34+FAbiYmhrwkJfywacxaGewu7Qynw9k6s4v7HR1ZW6LE3c2Zm6PXe7c3+l6lUqf8Vr3uz7c1y9tnw3HP5z3UwFq0pYczsAqCLu18dfn0p0Nbd++fY5qfwNivCrxcTKujuA6a4+xvh5a8AY9z9/VzvcS1wbfhlI2B+FD5KZWB9FNoNSnH7PKDPVFRE4zPVc/cqBdxmoYngGFYc/x/kVtw/Y3H/fFD8P2O0Pl/Ex69o9qytBOrkeF07vGx/26wwswTg/9u7/xg7qjKM498nTQFTDAgaYkRttSWkRtwaBQzVrA3Wqk0JUYgVDQRNiCkEo0RRE0UaYtQoGP8wIjTFpoIVizYNsdRSozZAKe3a2mIFQ4libU0UVKIl0Nc/zll6ud27bnf37sw5fT7JZmfm7s497z0zZ9+dX+8ppBsNxvK7RMStwK2T2OajSNoWEW/r53tMpdriAcdUihpjmqj/N4YdD59Z7THWHh/UH2Mb4uvnUyofBuZImiXpBNINA+u6fmYdcHme/hBwf6RDfeuAD0s6UdIsYA6wtY9tNTMzM2ulvh1Zy9egXQ1sID26Y0VE7JZ0I7AtItYBtwOr8g0EfycldOSfW0O6GeF5YNlU3wlqZmZm1gZ9fc5aRNwL3Nu17Esd0/8FLunxuzcBN/WzfWPU19OsDagtHnBMpagxpn47Hj6z2mOsPT6oP8bG4+vbDQZmZmZmNnGurGxmZmbWYk7WepC0T9IuSUOStjXdnvGQtELSwfyIlOFlp0naKOmx/P0VTbbxWPWI6QZJT+W+GpL0/ibbeKwkvVbSZkl7JO2WdG1eXmRfjRJP0f001SQtkrRX0uOSrm+6PZOhxjGpU237cjdJJ0naKum3Ob6v5OWzJD2Ut9Uf5ZsKiyVpmqQdktbn+cbjc7I2undHxEDTt+xOwEpgUdey6ymkaIUAAAW0SURBVIFNETEH2JTnS7KSo2MCuDn31UC+VrIkzwOfiYi5wPnAslxyrdS+6hUPlN1PU6ajXN/7gLnA0o7PsGQrqW9M6lTbvtztELAgIt4CDACLJJ1PKhV5c0TMBv5BKiVZsmuBRzvmG4/PyVrFIuJXpLtsO10E3JGn7wCKelR8j5iKFhH7I2J7nv4XaZB4DYX21Sjx2Ni9WK4vIp4Dhsv1Fa3GMalTbftyt0j+nWen568AFpBKRkLB8QFIOhP4AHBbnhctiM/JWm8B3CfpkfyU8VqcERH78/RfgTOabMwkulrSznyapchTDACSZgLzgIeooK+64oFK+mkKjFSur9aEt/jtfCS17cvD8inCIeAgsBH4I/B0RAwXkyp9W70F+CxwOM+fTgvic7LW2/yIeCvpNMQySe9qukGTLT+AuIbbgb8LvJF0WH4/8M1mmzM+kk4GfgJ8KiL+2flaiX01QjxV9JP1T4nb+Uhq25c7RcQLETFAqix0LnB2w02aNJIWAwcj4pGm29LNyVoPEfFU/n4QuIe0UdbggKRXA+TvBxtuz4RFxIE8gBwGvk+BfSVpOmlwXx0Ra/PiYvtqpHhq6KcpNKaSe5UodjsfSW37ci8R8TSwGXgHcKpSyUgoe1u9AFgiaR/p0oMFwLdpQXxO1kYgaYaklw9PAwuB343+W8XoLPF1OfCzBtsyKYYHwexiCuurfE3E7cCjEfGtjpeK7Kte8ZTeT1NsLOX6alHkdj6S2vblbpJeJenUPP0y4D2k6/I2k0pGQsHxRcTnI+LMiJhJ2ufuj4jLaEF8fijuCCS9gXQ0DVKVhx/migpFkXQnMAi8EjgAfBn4KbAGeB3wJHBpRBRzwX6PmAZJp9YC2Adc1XF9SOtJmg/8GtjFkeskvkC61qW4vholnqUU3E9TLT/a5BaOlOsrbgzqVuOY1Km2fbmbpHNIF9hPIx3sWRMRN+a/mXcBpwE7gI9GxKHmWjpxkgaB6yJicRvic7JmZmZm1mI+DWpmZmbWYk7WzMzMzFrMyZqZmZlZizlZMzMzM2sxJ2tmZmZmLeZkzczMzKzFnKxZNSQNSlrfdDvMzLpJeqek3ZKG8gNlu1+fKckPirYROVmz4nSU/TAzaw0lvf6uXgZ8NSIGIuI/U9kuK5+TNWtc/o/y95JWSvqDpNWSLpS0RdJjks6VdIOkVZK2AKvGsM4ZklZI2ipph6SL8vIrJK2V9PO87q/3PUAzq1Yev/ZK+gGphNrHJD0gabukH0s6WdIngEuB5ZJWj2Gd0yR9Q9LDknZKuiovH5T0S0l35zFzdS5xZZXzEQpri9nAJcCVpLqIHwHmA0tI5VqGgLnA/DH+V/pFUl23K3Mtu62SfpFfGwDmAYeAvZK+ExF/mtRozOx4ModUM/JxYC1wYUQ8K+lzwKdzSab5wPqIuHsM6/s48ExEvF3SicAWSffl1+YBbwL+AmwhFR//zSTHYy3jZM3a4omI2AUgaTewKSJC0i5gJilZW3cMpw8WAkskXZfnTyLV5SOv+5n8XnuA1wNO1sxsvJ6MiAclLSb9U7klH/A6AXhgHOtbCJwjabh4+CmkhPA5YGtE/BlA0hBpfHSyVjkna9YWnUVxD3fMH+bIdvrsMaxPwAcjYu9LFkrndb3XC3g/MLOJGR6bBGyMiKUTXJ+AayJiw0sWpuLiHr+OQ75mzWq1Abhm+HoOSfMabo+Z1e9B4AJJs+HFa2fPGsd6NgCflDQ9r+csSTMmsZ1WGCdrVqvlwHRgZz6turzh9phZ5SLib8AVwJ2SdpJOgZ49jlXdBuwBtufHeXwPH0E7rikimm6DmZmZmfXgI2tmZmZmLebDqlYcSe8Fvta1+ImIuLiJ9piZjZWkN3P0syIPRcR5TbTHyuDToGZmZmYt5tOgZmZmZi3mZM3MzMysxZysmZmZmbWYkzUzMzOzFnOyZmZmZtZi/wNgDRvM9D53AgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# what is the age distribution?\n",
    "fig, axs = plt.subplots(ncols=2, sharey=True, figsize=(10, 5))\n",
    "sns.distplot(data['mr_len'],kde_kws={'color': 'green'}, ax=axs[0], label='mr');\n",
    "axs[0].set(title='mr length Distribution')\n",
    "axs[0].set(ylabel='Probability Density')\n",
    "sns.distplot(data['ref_len'], kde_kws={'color': 'blue'}, ax=axs[1], label='ref' );\n",
    "axs[1].set(title='ref length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['mr_len', 'ref_len'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9344, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cnn = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mr</th>\n",
       "      <th>ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[name, cocum, eattype, coffee, shop, food, eng...</td>\n",
       "      <td>[cocum, cheap, chinese, coffee, shop, family, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[name, the, eagle, customer, rating, 5, out, o...</td>\n",
       "      <td>[eagle, city, centre, near, caf, brazil, famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[name, cotto, eattype, coffee, shop, food, eng...</td>\n",
       "      <td>[area, riverside, near, portland, arms, cotto,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[name, the, wrestlers, eattype, coffee, shop, ...</td>\n",
       "      <td>[wrestlers, family, friendly, venue, near, sor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[name, the, punter, customer, rating, average,...</td>\n",
       "      <td>[punter, family, friendly, place, riverside, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                 mr  \\\n",
       "0      1  [name, cocum, eattype, coffee, shop, food, eng...   \n",
       "1      0  [name, the, eagle, customer, rating, 5, out, o...   \n",
       "2      0  [name, cotto, eattype, coffee, shop, food, eng...   \n",
       "3      1  [name, the, wrestlers, eattype, coffee, shop, ...   \n",
       "4      1  [name, the, punter, customer, rating, average,...   \n",
       "\n",
       "                                                 ref  \n",
       "0  [cocum, cheap, chinese, coffee, shop, family, ...  \n",
       "1  [eagle, city, centre, near, caf, brazil, famil...  \n",
       "2  [area, riverside, near, portland, arms, cotto,...  \n",
       "3  [wrestlers, family, friendly, venue, near, sor...  \n",
       "4  [punter, family, friendly, place, riverside, a...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cnn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only the first words \n",
    "data_cnn['mr'] = data_cnn['mr'].apply(lambda x: x + ['']*(40 - len(x)) if len(x) < 40 else x[:40])\n",
    "data_cnn['ref'] = data_cnn['ref'].apply(lambda x: x + ['']*(40 - len(x)) if len(x) < 40 else x[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mr</th>\n",
       "      <th>ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[name, cocum, eattype, coffee, shop, food, eng...</td>\n",
       "      <td>[cocum, cheap, chinese, coffee, shop, family, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[name, the, eagle, customer, rating, 5, out, o...</td>\n",
       "      <td>[eagle, city, centre, near, caf, brazil, famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[name, cotto, eattype, coffee, shop, food, eng...</td>\n",
       "      <td>[area, riverside, near, portland, arms, cotto,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[name, the, wrestlers, eattype, coffee, shop, ...</td>\n",
       "      <td>[wrestlers, family, friendly, venue, near, sor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[name, the, punter, customer, rating, average,...</td>\n",
       "      <td>[punter, family, friendly, place, riverside, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                 mr  \\\n",
       "0      1  [name, cocum, eattype, coffee, shop, food, eng...   \n",
       "1      0  [name, the, eagle, customer, rating, 5, out, o...   \n",
       "2      0  [name, cotto, eattype, coffee, shop, food, eng...   \n",
       "3      1  [name, the, wrestlers, eattype, coffee, shop, ...   \n",
       "4      1  [name, the, punter, customer, rating, average,...   \n",
       "\n",
       "                                                 ref  \n",
       "0  [cocum, cheap, chinese, coffee, shop, family, ...  \n",
       "1  [eagle, city, centre, near, caf, brazil, famil...  \n",
       "2  [area, riverside, near, portland, arms, cotto,...  \n",
       "3  [wrestlers, family, friendly, venue, near, sor...  \n",
       "4  [punter, family, friendly, place, riverside, a...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cnn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the questions\n",
    "questions = data_cnn['mr'].append(data_cnn['ref'], ignore_index=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "# build word2vec model using only 200 features\n",
    "num_features = 200\n",
    "min_word_count = 1\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "context_size = 5\n",
    "downsampling = 1e-3\n",
    "seed = 10\n",
    "sg=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models.word2vec as w2v\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "FILENAME = 'models/model.w2v'\n",
    "class Word2VecModel(object):\n",
    "    '''In domain word embeddings model using word2vec algorithm'''\n",
    "    def __init__(self):\n",
    "        self._model = None\n",
    "        self.filename = FILENAME\n",
    "        \n",
    "    @classmethod\n",
    "    def from_file(cls, filename):\n",
    "        self = cls()\n",
    "        self._model = w2v.Word2Vec.load(filename)\n",
    "        self.filename = filename\n",
    "        return self\n",
    "        \n",
    "    def create_w2v_model(self, sentences, num_features, min_word, context,\n",
    "                         sg, downsampling, seed):\n",
    "        '''\n",
    "        Builds the word2vec model from a corpus of text.\n",
    "        :param sentences: List of list of string, the corpus.\n",
    "        :param num_features: Integer, embedding length.\n",
    "        :param min_word: Integer, the algorithm will ignore all word with frequency lower than min_word.\n",
    "        :param context: Integer, window size, the maximum distance between the current and predicted word within the sentence.\n",
    "        :param sg: Integer - 0 or 1 -, which indicates whether to use the skip-gram archittecture (1), or the continuous bag of words archittecture (0).\n",
    "        :param downsampling: Threshold for configuring which higher-frequency words are randomly downsampled;\n",
    "        :param seed: Integer, a random seed.\n",
    "        :return: the word2vec model\n",
    "        '''\n",
    "    \n",
    "        # define parameters\n",
    "        num_features = num_features\n",
    "        min_word_count = min_word\n",
    "        num_workers = multiprocessing.cpu_count()\n",
    "        context = context\n",
    "        downsampling = downsampling\n",
    "    \n",
    "        # create model\n",
    "        model = w2v.Word2Vec(sg=sg, seed=seed,  workers=num_workers, \\\n",
    "                             size=num_features, min_count=min_word_count, \\\n",
    "                             window=context, sample=downsampling )\n",
    "    \n",
    "        model.build_vocab(sentences)\n",
    "        model.train(sentences, total_examples=model.corpus_count, epochs=model.iter )\n",
    "        self._model = model\n",
    "        model.save(self.filename)\n",
    "\n",
    "    def get_w2v_vector(self, sentence, vector_size):\n",
    "        '''\n",
    "        Gets the word representations of a given sentence.\n",
    "        :param sentence: List of string, the input sentence.\n",
    "        :param vector_size: Integer, embedding size.\n",
    "        :return: A list of word representations.\n",
    "        '''\n",
    "    \n",
    "        sentence_len = len(sentence)\n",
    "        sentence2vec = np.zeros(shape=(sentence_len, vector_size), dtype='float32')\n",
    "        for i in range(sentence_len):\n",
    "            word = sentence[i]\n",
    "            word_vector = self._model[word]\n",
    "            sentence2vec[i] = word_vector\n",
    "    \n",
    "        return sentence2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2VecModel()\n",
    "model.create_w2v_model(questions, num_features, min_word_count, context_size,\n",
    "                         sg, downsampling, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v_vector(self, sentence, vector_size):\n",
    "        '''\n",
    "        Gets the word representations of a given sentence.\n",
    "        :param sentence: List of string, the input sentence.\n",
    "        :param vector_size: Integer, embedding size.\n",
    "        :return: A list of word representations.\n",
    "        '''\n",
    "    \n",
    "        sentence_len = len(sentence)\n",
    "        sentence2vec = np.zeros(shape=(sentence_len, vector_size), dtype='float32')\n",
    "        for i in range(sentence_len):\n",
    "            word = sentence[i]\n",
    "            word_vector = self._model[word]\n",
    "            sentence2vec[i] = word_vector\n",
    "    \n",
    "        return sentence2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cnn['mr'] = data_cnn['mr'].apply(lambda x: get_w2v_vector(model, x, vector_size=200))\n",
    "data_cnn['ref'] = data_cnn['ref'].apply(lambda x: get_w2v_vector(model, x, vector_size=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9344, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the shape\n",
    "data_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a data into fake and not fake\n",
    "data_fake = data_cnn[data_cnn['label'] == 1]\n",
    "data_nonfake = data_cnn[data_cnn['label'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of fake \n",
    "number_elt = data_fake.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample non duplicate data so that fake and non fake have the same size\n",
    "non_fake = data_nonfake.sample(n=number_elt, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cnn_final = pd.concat([non_fake, data_fake])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and test dataset \n",
    "train, test = train_test_split(data_cnn_final, test_size=0.1, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8409, 3)\n",
      "(935, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_pickle('cnn_train.pickle')\n",
    "test.to_pickle('cnn_test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a copy \n",
    "data_xgb = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punctuation(txt):\n",
    "    '''\n",
    "    Removes punctuations in a given sentence.\n",
    "    :param txt: String, input sentence.\n",
    "    :return: a list of words from the input sentence without punctuation.\n",
    "    '''\n",
    "    return [w for w in txt if w not in string.punctuation]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation in our corpus\n",
    "data_xgb['mr'] = data_xgb['mr'].apply(lambda x: remove_punctuation(x))\n",
    "data_xgb['ref'] = data_xgb['ref'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(txt):\n",
    "    '''\n",
    "    Removes english stopword in a given sentence.\n",
    "    :param txt: String, the input sentence.\n",
    "    :return: A list of words from the input sentence without any stopwords.\n",
    "    '''\n",
    "    return [w for w in txt if w not in stop_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords in our corpus\n",
    "data_xgb['mr'] = data_xgb['mr'].apply(remove_stopwords)\n",
    "data_xgb['ref'] = data_xgb['ref'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mr</th>\n",
       "      <th>ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[name, cocum, eattype, coffee, shop, food, eng...</td>\n",
       "      <td>[cocum, cheap, chinese, coffee, shop, family, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[name, eagle, customer, rating, 5, 5, area, ci...</td>\n",
       "      <td>[eagle, city, centre, near, caf, brazil, famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[name, cotto, eattype, coffee, shop, food, eng...</td>\n",
       "      <td>[area, riverside, near, portland, arms, cotto,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[name, wrestlers, eattype, coffee, shop, food,...</td>\n",
       "      <td>[wrestlers, family, friendly, venue, near, sor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[name, punter, customer, rating, average, area...</td>\n",
       "      <td>[punter, family, friendly, place, riverside, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                 mr  \\\n",
       "0      1  [name, cocum, eattype, coffee, shop, food, eng...   \n",
       "1      0  [name, eagle, customer, rating, 5, 5, area, ci...   \n",
       "2      0  [name, cotto, eattype, coffee, shop, food, eng...   \n",
       "3      1  [name, wrestlers, eattype, coffee, shop, food,...   \n",
       "4      1  [name, punter, customer, rating, average, area...   \n",
       "\n",
       "                                                 ref  \n",
       "0  [cocum, cheap, chinese, coffee, shop, family, ...  \n",
       "1  [eagle, city, centre, near, caf, brazil, famil...  \n",
       "2  [area, riverside, near, portland, arms, cotto,...  \n",
       "3  [wrestlers, family, friendly, venue, near, sor...  \n",
       "4  [punter, family, friendly, place, riverside, a...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "##prepare the data to build the LSA model\n",
    "data1 = data_xgb.mr\n",
    "data2 = data_xgb.ref\n",
    "data_q1 = []\n",
    "data_q2 = []\n",
    "q1_q2 = []\n",
    "for d in data1:\n",
    "    d1 = ' '.join(d)\n",
    "    data_q1.append(d1)\n",
    "    \n",
    "for d in data2:\n",
    "    d2 = ' '.join(d)\n",
    "    data_q2.append(d2)\n",
    "# our document set consist of all the questions: questions1 and questions2    \n",
    "q1_q2 = data_q1 + data_q2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidfvectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_i...vd', TruncatedSVD(algorithm='arpack', n_components=200, n_iter=5, random_state=10,\n",
       "       tol=0.0))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_clf = make_pipeline(TfidfVectorizer(min_df=1),\n",
    "                               TruncatedSVD(algorithm='arpack', n_components=200, random_state=seed))\n",
    "svd_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "svd_clf.fit(q1_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply trainsform to mr and ref  to get SVD vectors\n",
    "mr_transform = svd_clf.transform(data_q1)\n",
    "ref_transform = svd_clf.transform(data_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(q1, q2):\n",
    "    '''\n",
    "    Computes the similarity score between lists of vectors.\n",
    "    :param q1: List of the first vector.\n",
    "    :param q2: List of the second vector.\n",
    "    :return: A list of similarity score between vectors in q1 and q2.\n",
    "    '''\n",
    "    sim = []\n",
    "    for el1, el2 in zip(q1, q2):\n",
    "        sim.append(cosine_sim(el1, el2))\n",
    "\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(u, v):\n",
    "    '''\n",
    "    Computes the cosine similarity between two vectors u and v.\n",
    "    :param u: Numpy ndarray, the vector u.\n",
    "    :param v: Numpy ndarray, the vector v.\n",
    "    :return: Float between 0 and 1, the cosine similarity score between the vector u and v.\n",
    "    '''\n",
    "    return np.dot(u,v) / (norm(u)*norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity score\n",
    "sim = similarity(mr_transform, ref_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb['similarity'] = sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# other feature engineering\n",
    "### number of word in question 1\n",
    "data_xgb['q1_len'] = data_xgb['mr'].apply(len)\n",
    "### number of word in question 2\n",
    "data_xgb['q2_len'] = data_xgb['ref'].apply(len)\n",
    "### number of unique word in question 1\n",
    "data_xgb['q1_voc_len'] = data_xgb['mr'].apply(lambda x: len(list(set(x))))\n",
    "### number of unique word in question 2\n",
    "data_xgb['q2_voc_len'] = data_xgb['ref'].apply(lambda x: len(list(set(x))))\n",
    "### number of unique word in both question 1 and question 2\n",
    "data_xgb['shared_token_len'] = data_xgb.apply(lambda row: len(list(set(row['mr']) & set(row['ref']))), axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nan\n",
    "# remove NAN iN similarity\n",
    "ind_sim = data_xgb[data_xgb.similarity.isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ind_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb.drop(ind_sim, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop the column we won't need\n",
    "data_xgb.drop(['mr', 'ref'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_xgb[['similarity', 'q1_len', 'q2_len', 'q1_voc_len', 'q2_voc_len', 'shared_token_len']].plot(kind= 'density',\n",
    "                                                                                                    figsize=(15, 10),\n",
    "                                                                                                    subplots=True, layout=(2,3),\n",
    "                                                                                                    sharex=False, sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xgb_features = data_xgb[['similarity', 'q1_len', 'q2_len', 'q1_voc_len', 'q2_voc_len', 'shared_token_len']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(data_xgb_features.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#correlation matrix\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(data_xgb_features.corr(),vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,6,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(names)\n",
    "ax.set_yticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# xgboost tree\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(data_xgb.drop('label',1), data_xgb.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo importance figure\n",
    "plot_importance(xgb_model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split the data into training and test dataset \n",
    "train_xgb, test_xgb = train_test_split(data_xgb, test_size=0.1, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### save data for xgboost learning\n",
    "train_xgb.to_pickle('xgb_train.pickle')\n",
    "test_xgb.to_pickle('xgb_test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fbeta(threshold_shift):\n",
    "    def fbeta(y_true, y_pred, beta=1):\n",
    "        '''\n",
    "        Compute fbeta score.\n",
    "        :param y_true: y_true\n",
    "        :param y_pred: predicted value\n",
    "        :param threshold_shift: threshold\n",
    "        :param beta: beta value\n",
    "        :return: fbeta score\n",
    "    \n",
    "    '''\n",
    "    # just in case of hipster activation at the final layer\n",
    "        y_pred = K.clip(y_pred, 0, 1)\n",
    "        y_true = K.clip(y_true, 0, 1)\n",
    "    \n",
    "    # shifting the prediction threshold from .5 if needed\n",
    "        y_pred_bin = K.round(y_pred + threshold_shift)\n",
    "    \n",
    "        tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n",
    "        fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n",
    "        fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n",
    "    \n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "    \n",
    "        beta_squared = beta ** 2\n",
    "        return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())\n",
    "    return fbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbeta01 = make_fbeta(0.1)\n",
    "fbeta02 = make_fbeta(0.2)\n",
    "fbeta03 = make_fbeta(0.3)\n",
    "fbeta04 = make_fbeta(0.4)\n",
    "fbeta00 = make_fbeta(0.0)\n",
    "fbeta_minus01 = make_fbeta(-0.1)\n",
    "fbeta_minus02 = make_fbeta(-0.2)\n",
    "fbeta_minus03 = make_fbeta(-0.3)\n",
    "fbeta_minus04 = make_fbeta(-0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, merge, Reshape, Dropout\n",
    "from keras.layers.merge import Dot\n",
    "from keras.constraints import max_norm\n",
    "\n",
    "FILEPATH = 'model_best.hdf5'\n",
    "\n",
    "\n",
    "class CnnModel(object):\n",
    "    ''' Convolutional neural network model for question pair similarity '''\n",
    "    \n",
    "    def __init__(self, filter_size, strides, padding, embedding_len, activation,filters, k_initialization, b_initialization, input_shape, bias):\n",
    "        # initialize the model\n",
    "        self.filepath = FILEPATH\n",
    "        self.cnn_model = self._build_model(filter_size, strides, padding, embedding_len, activation,filters, k_initialization,\n",
    "                                           b_initialization, input_shape, bias)\n",
    "\n",
    "    @classmethod\n",
    "    def from_weights(cls, filepath, filter_size, strides, padding, embedding_len, activation,filters, k_initialization,\n",
    "                                           b_initialization, input_shape, bias):\n",
    "        \n",
    "        self = cls(filter_size, strides, padding, embedding_len, activation, filters,\n",
    "                                           k_initialization, b_initialization, input_shape, bias)\n",
    "        self.filepath = filepath\n",
    "        self.cnn_model.load_weights(filepath)\n",
    "        return self\n",
    "        \n",
    "\n",
    "    def _convolutional_layer(self, filter_size, strides, padding, \\\n",
    "                            embedding_len, activation, \\\n",
    "                            bias, k_initialization, b_initialization, filters ):\n",
    "        '''\n",
    "        Defines a list of 2D convolution operations.\n",
    "        :param filter_size: Integer, the dimensionality of the output space.\n",
    "        :param strides: An integer or tuple/list of 2 integers, specifying the stride of the convolution.\n",
    "        :param padding: Type of padding, one of  'valid' or 'same'.\n",
    "        :param embedding_len: An integer, specifying the width of the 2D convolution window.\n",
    "        :param activation: Activation function to use.\n",
    "        :param bias: Boolean, whether the layer uses a bias vector.\n",
    "        :param k_initialization: Initializer for the kernel weight matrix.\n",
    "        :param b_initialization: Initializer for the bias vector.\n",
    "        :param filters: A list of integer, specifying the different heights of the 2D convolution window.\n",
    "        :return: A list of 2D convolution operations.\n",
    "        '''\n",
    "    \n",
    "        cnns = [Conv2D(filters=filter_size, kernel_size=(filter_len, embedding_len), \\\n",
    "                       strides=strides, padding=padding, activation=activation,\n",
    "                       use_bias=bias, kernel_initializer=k_initialization,\n",
    "                       bias_initializer=b_initialization, kernel_constraint=max_norm(4.)) for filter_len in filters]\n",
    "    \n",
    "        return cnns\n",
    "    \n",
    "\n",
    "    def _input_sentence(self, shape):\n",
    "        '''\n",
    "        Defines the input shape.\n",
    "        :param shape: Tuple of input shape\n",
    "        :return: A tensor with shape (None, shape)\n",
    "        '''\n",
    "        return Input(shape=shape)\n",
    "    \n",
    "    def _cnn_sentences_layer(self, cnns, sentence):\n",
    "        '''\n",
    "        Computes a list of 2D convolution operations on an input sentence.\n",
    "        :param cnns: a list of 2D convolution operations.\n",
    "        :param sentence: input sentence.\n",
    "        :return: A list of 2D convolution layer.\n",
    "        '''\n",
    "        return [cnn(sentence) for cnn in cnns]\n",
    "    \n",
    "    \n",
    "    def _max_pool_sentences_layer(self, models, sentence_len, filters):\n",
    "       '''\n",
    "       Computes 2D max pooling operation.\n",
    "       :param models: List of input tensors.\n",
    "       :param sentence_len: Integer, the length of the sentence.\n",
    "       :param filters: List of filters.\n",
    "       :return: A list of tensor from the 2D max pooling operation.\n",
    "       '''\n",
    "       return [MaxPooling2D(pool_size=(sentence_len - filter_len + 1, 1))(model) for model, filter_len in zip(models, filters)]\n",
    "    \n",
    "    def _merge_concat_layer(self, model):\n",
    "        '''\n",
    "        Concatenates a list of tensors.\n",
    "        :param model: Tensors to concatenate\n",
    "        :return: A tensor from the concatenate operation.\n",
    "        '''\n",
    "        return  merge(model, mode='concat')\n",
    "    \n",
    "    def _merge_cosim_layer(self, model_1, model_2):\n",
    "        '''\n",
    "        Computes the cosine similarity between two tensors.\n",
    "        :param model_1: The first tensor.\n",
    "        :param model_2: The second tensor.\n",
    "        :return: The cosine similarity value between model_1 and model_2.\n",
    "        '''\n",
    "        return Dot(axes=1, normalize=True)([model_1, model_2])\n",
    "    \n",
    "    def  _build_model(self,filter_size, strides, padding, embedding_len, activation,filters, k_initialization, b_initialization, input_shape, bias, dropout=0.3):\n",
    "        '''\n",
    "        Defines the convolutional neural network model.\n",
    "        :param filter_size: Number of output.\n",
    "        :param strides: Stride.\n",
    "        :param padding: Padding value.\n",
    "        :param embedding_len: Filter width.\n",
    "        :param activation: Activation function.\n",
    "        :param filters: List of integer - filters heights.\n",
    "        :param k_initialization: Kernel initialization value.\n",
    "        :param b_initialization: Bias initialization values\n",
    "        :param input_shape: Input shape\n",
    "        :param bias: Boolean, whether to use bias.\n",
    "        :param dropout: Dropout value.\n",
    "        :return: Convolutional neural network model.\n",
    "        '''\n",
    "        sentence_len = input_shape[0]\n",
    "        \n",
    "        # define input\n",
    "        mr_input = self._input_sentence(input_shape)\n",
    "        ref_input =self._input_sentence(input_shape)\n",
    "    \n",
    "        # convolutional layer\n",
    "        cnns = self._convolutional_layer(filter_size, strides, padding, \\\n",
    "                            embedding_len, activation, \\\n",
    "                            bias, k_initialization, b_initialization, filters )\n",
    "    \n",
    "    \n",
    "        ## sentence 1 convolutional layer\n",
    "        mr_cnn_layer = self._cnn_sentences_layer(cnns, mr_input)\n",
    "        ## add dropout regularization parameter\n",
    "        mr_cnn_layer = [Dropout(dropout)(cnn) for cnn in mr_cnn_layer]\n",
    "    \n",
    "        ##sentence 2 convolutional layer\n",
    "        ref_cnn_layer = self._cnn_sentences_layer(cnns, ref_input)\n",
    "        ## add dropout regularization parameter\n",
    "        ref_cnn_layer = [Dropout(dropout)(cnn) for cnn in ref_cnn_layer]\n",
    "    \n",
    "        # Max pooling layer\n",
    "        ## sentence 1 max pooling layer\n",
    "        mr_max_pool = self._max_pool_sentences_layer(mr_cnn_layer, sentence_len, filters)\n",
    "    \n",
    "        ## ref max pooling layer\n",
    "        ref_max_pool = self._max_pool_sentences_layer(ref_cnn_layer, sentence_len, filters)\n",
    "    \n",
    "        # concat layer\n",
    "        ## Sentence 1 concat layer\n",
    "        mr_concat =  self._merge_concat_layer(mr_max_pool)\n",
    "    \n",
    "        ## ref concat layer\n",
    "        ref_concat = self._merge_concat_layer(ref_max_pool)\n",
    "    \n",
    "        # Flatten layer\n",
    "        ## sentence 1 flatten layer\n",
    "        mr_flatten = Reshape((-1, ))(mr_concat)\n",
    "    \n",
    "        ## ref Flatten layer\n",
    "        ref_flatten = Reshape((-1, ))(ref_concat)\n",
    "    \n",
    "        # Merge with cosine similarity layer\n",
    "        dot = self._merge_cosim_layer(mr_flatten, ref_flatten)\n",
    "        model = Model([mr_input, ref_input], [dot])\n",
    "    \n",
    "        return model\n",
    "    \n",
    "    def compile(self, loss, optimizer, metrics ):\n",
    "        '''\n",
    "        Configures the model for training.\n",
    "        :param loss:  String (name of objective function) or objective function.\n",
    "        :param optimizer: String (name of optimizer) or optimizer instance.\n",
    "        :param metrics: list of metrics to be evaluated by the model during training and testing.\n",
    "        '''\n",
    "        self.cnn_model.compile(loss=loss, optimizer=optimizer,  metrics=metrics)\n",
    "\n",
    "    def train(self, X_train, y_train, batch_size, epochs, validation_data, verbose=2, shuffle=True ):\n",
    "        '''\n",
    "        Trains the model for a fixed number of epochs.\n",
    "        :param X_train: List of Numpy arrays of training data.\n",
    "        :param y_train: List of Numpy arrays of target data.\n",
    "        :param batch_size: Number of samples per gradient update.\n",
    "        :param epochs: Number of epochs to train the model.\n",
    "        :param validation_data: Tuple on which to evaluate the loss and any model metric at the end of each epoch.\n",
    "        :param verbose: Verbosity mode - 0, 1, 2.\n",
    "        :param shuffle: Boolean (True or False)- whether to shuffle the training data before each epoch.\n",
    "        '''\n",
    "        checkpointer = ModelCheckpoint(filepath=self.filepath, verbose=1,\n",
    "                                   save_best_only=True)\n",
    "        \n",
    "        self.cnn_model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                         validation_data=validation_data,\n",
    "                         callbacks=[checkpointer],\n",
    "                         verbose=verbose, shuffle=shuffle)\n",
    "        \n",
    "    def evaluate(self, X_test, y_test, verbose=0):\n",
    "        '''\n",
    "        Returns the loss value and metrics values for the model in test mode.\n",
    "        :param X_test: List of Numpy array of test data.\n",
    "        :param y_test: List of Numpy array of target data.\n",
    "        :param verbose: Verbosity mode 0 or 1.\n",
    "        :return: List of scalar - test loss and metrics values.\n",
    "        '''\n",
    "        return self.cnn_model.evaluate(X_test, y_test, verbose=verbose)\n",
    "        \n",
    "        \n",
    "    def predict(self, x):\n",
    "        '''\n",
    "        Generates output predictions for the input samples.\n",
    "        :param x: List of Numpy array of the input data.\n",
    "        :return: Numpy array of predictions.\n",
    "        '''\n",
    "        return self.cnn_model.predict(x)\n",
    "    \n",
    "    def summary(self):\n",
    "        '''\n",
    "        Prints the summary representation of the model.\n",
    "        '''\n",
    "        self.cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# define parameters\n",
    "filter_size = 32\n",
    "strides = (1, 1)\n",
    "padding = 'VALID'\n",
    "embedding_len = 200\n",
    "activation = 'relu'\n",
    "filters = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "bias = True\n",
    "sentence_len = 40\n",
    "k_initialization = 'glorot_uniform'\n",
    "b_initialization = 'zeros'\n",
    "input_shape = (sentence_len, embedding_len, 1)\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "seed = 10\n",
    "\n",
    "# define metrics\n",
    "acc = make_accuracy(0)\n",
    "fbeta = make_fbeta(0)\n",
    "\n",
    "FILE_PATH = 'cnn_train.pickle'\n",
    "\n",
    "    # Prepare data\n",
    "data_cnn = pd.read_pickle(FILE_PATH)\n",
    "train, validation = train_test_split(data_cnn, test_size=0.1, random_state=seed)\n",
    "    \n",
    "    ## Traning data\n",
    "mr_train = train.mr.tolist()\n",
    "ref_train = train.ref.tolist()\n",
    "y_train = train.label.tolist()\n",
    "question_1_train, question_2_train, y_train = reshape_data(mr_train, ref_train, y_train)\n",
    "    \n",
    "    ## Validation data\n",
    "mr_validation = validation.mr.tolist()\n",
    "ref_validation = validation.ref.tolist()\n",
    "y_validation = validation.label.tolist()\n",
    "question_1_validation, question_2_validation, y_validation = reshape_data(mr_validation,\n",
    "                                                                              ref_validation, y_validation)\n",
    "\n",
    "    # Define the model\n",
    "cnn_model = CnnModel(filter_size, strides, padding, embedding_len, activation, filters, k_initialization,\n",
    "                         b_initialization, input_shape, bias)\n",
    "cnn_model.summary()\n",
    "cnn_model.compile(loss='mean_squared_error', optimizer='adam', metrics=[acc, fbeta])\n",
    "    \n",
    "    # Train the model\n",
    "cnn_model.train([question_1_train, question_2_train], y_train, batch_size=batch_size, epochs=epochs,\n",
    "                    validation_data=([question_1_validation, question_2_validation], y_validation),\n",
    "                    verbose=2, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
